{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "            FastQC - A high throughput sequence QC analysis tool\r\n",
      "\r\n",
      "SYNOPSIS\r\n",
      "\r\n",
      "\tfastqc seqfile1 seqfile2 .. seqfileN\r\n",
      "\r\n",
      "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \r\n",
      "           [-c contaminant file] seqfile1 .. seqfileN\r\n",
      "\r\n",
      "DESCRIPTION\r\n",
      "\r\n",
      "    FastQC reads a set of sequence files and produces from each one a quality\r\n",
      "    control report consisting of a number of different modules, each one of \r\n",
      "    which will help to identify a different potential type of problem in your\r\n",
      "    data.\r\n",
      "    \r\n",
      "    If no files to process are specified on the command line then the program\r\n",
      "    will start as an interactive graphical application.  If files are provided\r\n",
      "    on the command line then the program will run with no user interaction\r\n",
      "    required.  In this mode it is suitable for inclusion into a standardised\r\n",
      "    analysis pipeline.\r\n",
      "    \r\n",
      "    The options for the program as as follows:\r\n",
      "    \r\n",
      "    -h --help       Print this help file and exit\r\n",
      "    \r\n",
      "    -v --version    Print the version of the program and exit\r\n",
      "    \r\n",
      "    -o --outdir     Create all output files in the specified output directory.\r\n",
      "                    Please note that this directory must exist as the program\r\n",
      "                    will not create it.  If this option is not set then the \r\n",
      "                    output file for each sequence file is created in the same\r\n",
      "                    directory as the sequence file which was processed.\r\n",
      "                    \r\n",
      "    --casava        Files come from raw casava output. Files in the same sample\r\n",
      "                    group (differing only by the group number) will be analysed\r\n",
      "                    as a set rather than individually. Sequences with the filter\r\n",
      "                    flag set in the header will be excluded from the analysis.\r\n",
      "                    Files must have the same names given to them by casava\r\n",
      "                    (including being gzipped and ending with .gz) otherwise they\r\n",
      "                    won't be grouped together correctly.\r\n",
      "                    \r\n",
      "    --nano          Files come from nanopore sequences and are in fast5 format. In\r\n",
      "                    this mode you can pass in directories to process and the program\r\n",
      "                    will take in all fast5 files within those directories and produce\r\n",
      "                    a single output file from the sequences found in all files.                    \r\n",
      "                    \r\n",
      "    --nofilter      If running with --casava then don't remove read flagged by\r\n",
      "                    casava as poor quality when performing the QC analysis.\r\n",
      "                   \r\n",
      "    --extract       If set then the zipped output file will be uncompressed in\r\n",
      "                    the same directory after it has been created.  By default\r\n",
      "                    this option will be set if fastqc is run in non-interactive\r\n",
      "                    mode.\r\n",
      "                    \r\n",
      "    -j --java       Provides the full path to the java binary you want to use to\r\n",
      "                    launch fastqc. If not supplied then java is assumed to be in\r\n",
      "                    your path.\r\n",
      "                   \r\n",
      "    --noextract     Do not uncompress the output file after creating it.  You\r\n",
      "                    should set this option if you do not wish to uncompress\r\n",
      "                    the output when running in non-interactive mode.\r\n",
      "                    \r\n",
      "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\r\n",
      "                    show data for every base in the read.  WARNING: Using this\r\n",
      "                    option will cause fastqc to crash and burn if you use it on\r\n",
      "                    really long reads, and your plots may end up a ridiculous size.\r\n",
      "                    You have been warned!\r\n",
      "                    \r\n",
      "    --min_length    Sets an artificial lower limit on the length of the sequence\r\n",
      "                    to be shown in the report.  As long as you set this to a value\r\n",
      "                    greater or equal to your longest read length then this will be\r\n",
      "                    the sequence length used to create your read groups.  This can\r\n",
      "                    be useful for making directly comaparable statistics from \r\n",
      "                    datasets with somewhat variable read lengths.\r\n",
      "                    \r\n",
      "    -f --format     Bypasses the normal sequence file format detection and\r\n",
      "                    forces the program to use the specified format.  Valid\r\n",
      "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\r\n",
      "                    \r\n",
      "    -t --threads    Specifies the number of files which can be processed\r\n",
      "                    simultaneously.  Each thread will be allocated 250MB of\r\n",
      "                    memory so you shouldn't run more threads than your\r\n",
      "                    available memory will cope with, and not more than\r\n",
      "                    6 threads on a 32 bit machine\r\n",
      "                  \r\n",
      "    -c              Specifies a non-default file which contains the list of\r\n",
      "    --contaminants  contaminants to screen overrepresented sequences against.\r\n",
      "                    The file must contain sets of named contaminants in the\r\n",
      "                    form name[tab]sequence.  Lines prefixed with a hash will\r\n",
      "                    be ignored.\r\n",
      "\r\n",
      "    -a              Specifies a non-default file which contains the list of\r\n",
      "    --adapters      adapter sequences which will be explicity searched against\r\n",
      "                    the library. The file must contain sets of named adapters\r\n",
      "                    in the form name[tab]sequence.  Lines prefixed with a hash\r\n",
      "                    will be ignored.\r\n",
      "                    \r\n",
      "    -l              Specifies a non-default file which contains a set of criteria\r\n",
      "    --limits        which will be used to determine the warn/error limits for the\r\n",
      "                    various modules.  This file can also be used to selectively \r\n",
      "                    remove some modules from the output all together.  The format\r\n",
      "                    needs to mirror the default limits.txt file found in the\r\n",
      "                    Configuration folder.\r\n",
      "                    \r\n",
      "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\r\n",
      "                    module. Specified Kmer length must be between 2 and 10. Default\r\n",
      "                    length is 7 if not specified.\r\n",
      "                    \r\n",
      "   -q --quiet       Supress all progress messages on stdout and only report errors.\r\n",
      "   \r\n",
      "   -d --dir         Selects a directory to be used for temporary files written when\r\n",
      "                    generating report images. Defaults to system temp directory if\r\n",
      "                    not specified.\r\n",
      "                    \r\n",
      "BUGS\r\n",
      "\r\n",
      "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\r\n",
      "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\r\n",
      "                   \r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "#Installing FastQC and getting it to run via command line\n",
    "!/Applications/FastQC/fastqc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Forward Reads (R1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 5% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 10% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 15% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 20% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 25% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 30% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 35% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 40% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 45% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 50% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 55% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 60% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 65% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 70% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 75% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 80% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 85% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 90% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Approx 95% complete for Good-lib1_S1_L001_R1_001.fastq\n",
      "Analysis complete for Good-lib1_S1_L001_R1_001.fastq\n"
     ]
    }
   ],
   "source": [
    "!/Applications/FastQC/fastqc \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/Good-lib1_S1_L001_R1_001.fastq \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Reverse Reads (R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 5% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 10% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 15% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 20% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 25% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 30% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 35% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 40% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 45% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 50% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 55% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 60% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 65% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 70% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 75% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 80% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 85% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 90% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Approx 95% complete for Good-lib1_S1_L001_R2_001.fastq\n",
      "Analysis complete for Good-lib1_S1_L001_R2_001.fastq\n"
     ]
    }
   ],
   "source": [
    "!/Applications/FastQC/fastqc \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/Good-lib1_S1_L001_R2_001.fastq \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairing the forward and reverse files in pear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ____  _____    _    ____ \n",
      "|  _ \\| ____|  / \\  |  _ \\\n",
      "| |_) |  _|   / _ \\ | |_) |\n",
      "|  __/| |___ / ___ \\|  _ <\n",
      "|_|   |_____/_/   \\_\\_| \\_\\\n",
      "\n",
      "PEAR v0.9.11 [Nov 5, 2017]\n",
      "\n",
      "Citation - PEAR: a fast and accurate Illumina Paired-End reAd mergeR\n",
      "Zhang et al (2014) Bioinformatics 30(5): 614-620 | doi:10.1093/bioinformatics/btt593\n",
      "\n",
      "Forward reads file.................: /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/Good-lib1_S1_L001_R1_001.fastq\n",
      "Reverse reads file.................: /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/Good-lib1_S1_L001_R2_001.fastq\n",
      "PHRED..............................: 33\n",
      "Using empirical frequencies........: YES\n",
      "Statistical method.................: OES\n",
      "Maximum assembly length............: 999999\n",
      "Minimum assembly length............: 350\n",
      "p-value............................: 0.010000\n",
      "Quality score threshold (trimming).: 0\n",
      "Minimum read size after trimming...: 1\n",
      "Maximal ratio of uncalled bases....: 0.000000\n",
      "Minimum overlap....................: 10\n",
      "Scoring method.....................: Scaled score\n",
      "Threads............................: 1\n",
      "\n",
      "Allocating memory..................: 200,000,000 bytes\n",
      "Computing empirical frequencies....: DONE\n",
      "  A: 0.287156\n",
      "  C: 0.207011\n",
      "  G: 0.216746\n",
      "  T: 0.289087\n",
      "  31536 uncalled bases\n",
      "Assemblying reads: 100%\n",
      "\n",
      "Assembled reads ...................: 1,844,518 / 2,386,309 (77.296%)\n",
      "Discarded reads ...................: 541,791 / 2,386,309 (22.704%)\n",
      "Not assembled reads ...............: 0 / 2,386,309 (0.000%)\n",
      "Assembled reads file...............: /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Merged/Lib-1.fastq.assembled.fastq\n",
      "Discarded reads file...............: /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Merged/Lib-1.fastq.discarded.fastq\n",
      "Unassembled forward reads file.....: /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Merged/Lib-1.fastq.unassembled.forward.fastq\n",
      "Unassembled reverse reads file.....: /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Merged/Lib-1.fastq.unassembled.reverse.fastq\n"
     ]
    }
   ],
   "source": [
    "#added a max length of 350 and added quality control\n",
    "!pear \\\n",
    "-f /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/Good-lib1_S1_L001_R1_001.fastq \\\n",
    "-r /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Raw/Good-lib1_S1_L001_R2_001.fastq \\\n",
    "-n 350 \\\n",
    "-u 0 \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Merged/Lib-1.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward and reverse Fastq files are now merged. A max length of 350 and quality control were added. This resulted in 4 fastq files in the \"Merged\" folder of the repository. 1 assembled, 1 discarded, and 2 unassembled. The assembled file will be the one used moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The next step is to convert FASTQ to FASTA using seqtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   seqtk <command> <arguments>\r\n",
      "Version: 1.3-r106\r\n",
      "\r\n",
      "Command: seq       common transformation of FASTA/Q\r\n",
      "         comp      get the nucleotide composition of FASTA/Q\r\n",
      "         sample    subsample sequences\r\n",
      "         subseq    extract subsequences from FASTA/Q\r\n",
      "         fqchk     fastq QC (base/quality summary)\r\n",
      "         mergepe   interleave two PE FASTA/Q files\r\n",
      "         trimfq    trim FASTQ using the Phred algorithm\r\n",
      "\r\n",
      "         hety      regional heterozygosity\r\n",
      "         gc        identify high- or low-GC regions\r\n",
      "         mutfa     point mutate FASTA at specified positions\r\n",
      "         mergefa   merge two FASTA/Q files\r\n",
      "         famask    apply a X-coded FASTA to a source FASTA\r\n",
      "         dropse    drop unpaired from interleaved PE FASTA/Q\r\n",
      "         rename    rename sequence names\r\n",
      "         randbase  choose a random base from hets\r\n",
      "         cutN      cut sequence at long N\r\n",
      "         listhet   extract the position of each het\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!seqtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!seqtk \\\n",
    "seq -a /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Merged/Lib-1.fastq.assembled.fastq > /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/FASTA/Lib-1.assembled.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove tags and split into 16 individual sequences using cutadapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutadapt version 1.17\r\n",
      "Copyright (C) 2010-2018 Marcel Martin <marcel.martin@scilifelab.se>\r\n",
      "\r\n",
      "cutadapt removes adapter sequences from high-throughput sequencing reads.\r\n",
      "\r\n",
      "Usage:\r\n",
      "    cutadapt -a ADAPTER [options] [-o output.fastq] input.fastq\r\n",
      "\r\n",
      "For paired-end reads:\r\n",
      "    cutadapt -a ADAPT1 -A ADAPT2 [options] -o out1.fastq -p out2.fastq in1.fastq in2.fastq\r\n",
      "\r\n",
      "Replace \"ADAPTER\" with the actual sequence of your 3' adapter. IUPAC wildcard\r\n",
      "characters are supported. The reverse complement is *not* automatically\r\n",
      "searched. All reads from input.fastq will be written to output.fastq with the\r\n",
      "adapter sequence removed. Adapter matching is error-tolerant. Multiple adapter\r\n",
      "sequences can be given (use further -a options), but only the best-matching\r\n",
      "adapter will be removed.\r\n",
      "\r\n",
      "Input may also be in FASTA format. Compressed input and output is supported and\r\n",
      "auto-detected from the file name (.gz, .xz, .bz2). Use the file name '-' for\r\n",
      "standard input/output. Without the -o option, output is sent to standard output.\r\n",
      "\r\n",
      "Citation:\r\n",
      "\r\n",
      "Marcel Martin. Cutadapt removes adapter sequences from high-throughput\r\n",
      "sequencing reads. EMBnet.Journal, 17(1):10-12, May 2011.\r\n",
      "http://dx.doi.org/10.14806/ej.17.1.200\r\n",
      "\r\n",
      "Use \"cutadapt --help\" to see all command-line options.\r\n",
      "See http://cutadapt.readthedocs.io/ for full documentation.\r\n",
      "\r\n",
      "Options:\r\n",
      "  --version             show program's version number and exit\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --debug               Print debugging information.\r\n",
      "  -f FORMAT, --format=FORMAT\r\n",
      "                        Input file format; can be either 'fasta', 'fastq' or\r\n",
      "                        'sra-fastq'. Ignored when reading csfasta/qual files.\r\n",
      "                        Default: auto-detect from file name extension.\r\n",
      "  -j CORES, --cores=CORES\r\n",
      "                        Number of CPU cores to use. Default: 1\r\n",
      "\r\n",
      "  Finding adapters:\r\n",
      "    Parameters -a, -g, -b specify adapters to be removed from each read\r\n",
      "    (or from the first read in a pair if data is paired). If specified\r\n",
      "    multiple times, only the best matching adapter is trimmed (but see the\r\n",
      "    --times option). When the special notation 'file:FILE' is used,\r\n",
      "    adapter sequences are read from the given FASTA file.\r\n",
      "\r\n",
      "    -a ADAPTER, --adapter=ADAPTER\r\n",
      "                        Sequence of an adapter ligated to the 3' end (paired\r\n",
      "                        data: of the first read). The adapter and subsequent\r\n",
      "                        bases are trimmed. If a '$' character is appended\r\n",
      "                        ('anchoring'), the adapter is only found if it is a\r\n",
      "                        suffix of the read.\r\n",
      "    -g ADAPTER, --front=ADAPTER\r\n",
      "                        Sequence of an adapter ligated to the 5' end (paired\r\n",
      "                        data: of the first read). The adapter and any\r\n",
      "                        preceding bases are trimmed. Partial matches at the 5'\r\n",
      "                        end are allowed. If a '^' character is prepended\r\n",
      "                        ('anchoring'), the adapter is only found if it is a\r\n",
      "                        prefix of the read.\r\n",
      "    -b ADAPTER, --anywhere=ADAPTER\r\n",
      "                        Sequence of an adapter that may be ligated to the 5'\r\n",
      "                        or 3' end (paired data: of the first read). Both types\r\n",
      "                        of matches as described under -a und -g are allowed.\r\n",
      "                        If the first base of the read is part of the match,\r\n",
      "                        the behavior is as with -g, otherwise as with -a. This\r\n",
      "                        option is mostly for rescuing failed library\r\n",
      "                        preparations - do not use if you know which end your\r\n",
      "                        adapter was ligated to!\r\n",
      "    -e RATE, --error-rate=RATE\r\n",
      "                        Maximum allowed error rate as value between 0 and 1\r\n",
      "                        (no. of errors divided by length of matching region).\r\n",
      "                        Default: 0.1 (=10%)\r\n",
      "    --no-indels         Allow only mismatches in alignments. Default: allow\r\n",
      "                        both mismatches and indels\r\n",
      "    -n COUNT, --times=COUNT\r\n",
      "                        Remove up to COUNT adapters from each read. Default: 1\r\n",
      "    -O MINLENGTH, --overlap=MINLENGTH\r\n",
      "                        Require MINLENGTH overlap between read and adapter for\r\n",
      "                        an adapter to be found. Default: 3\r\n",
      "    --match-read-wildcards\r\n",
      "                        Interpret IUPAC wildcards in reads. Default: False\r\n",
      "    -N, --no-match-adapter-wildcards\r\n",
      "                        Do not interpret IUPAC wildcards in adapters.\r\n",
      "    --no-trim           Match and redirect reads to output/untrimmed-output as\r\n",
      "                        usual, but do not remove adapters.\r\n",
      "    --mask-adapter      Mask adapters with 'N's instead of trimming them.\r\n",
      "\r\n",
      "  Additional read modifications:\r\n",
      "    -u LENGTH, --cut=LENGTH\r\n",
      "                        Remove bases from each read (first read only if\r\n",
      "                        paired). If LENGTH is positive, remove bases from the\r\n",
      "                        beginning. If LENGTH is negative, remove bases from\r\n",
      "                        the end. Can be used twice if LENGTHs have different\r\n",
      "                        signs. This is applied *before* adapter trimming.\r\n",
      "    --nextseq-trim=3'CUTOFF\r\n",
      "                        NextSeq-specific quality trimming (each read). Trims\r\n",
      "                        also dark cycles appearing as high-quality G bases.\r\n",
      "    -q [5'CUTOFF,]3'CUTOFF, --quality-cutoff=[5'CUTOFF,]3'CUTOFF\r\n",
      "                        Trim low-quality bases from 5' and/or 3' ends of each\r\n",
      "                        read before adapter removal. Applied to both reads if\r\n",
      "                        data is paired. If one value is given, only the 3' end\r\n",
      "                        is trimmed. If two comma-separated cutoffs are given,\r\n",
      "                        the 5' end is trimmed with the first cutoff, the 3'\r\n",
      "                        end with the second.\r\n",
      "    --quality-base=N    Assume that quality values in FASTQ are encoded as\r\n",
      "                        ascii(quality + N). This needs to be set to 64 for\r\n",
      "                        some old Illumina FASTQ files. Default: 33\r\n",
      "    -l LENGTH, --length=LENGTH\r\n",
      "                        Shorten reads to LENGTH. Positive values remove bases\r\n",
      "                        at the end while negative ones remove bases at the\r\n",
      "                        beginning. This and the following modifications are\r\n",
      "                        applied after adapter trimming.\r\n",
      "    --trim-n            Trim N's on ends of reads.\r\n",
      "    --length-tag=TAG    Search for TAG followed by a decimal number in the\r\n",
      "                        description field of the read. Replace the decimal\r\n",
      "                        number with the correct length of the trimmed read.\r\n",
      "                        For example, use --length-tag 'length=' to correct\r\n",
      "                        fields like 'length=123'.\r\n",
      "    --strip-suffix=STRIP_SUFFIX\r\n",
      "                        Remove this suffix from read names if present. Can be\r\n",
      "                        given multiple times.\r\n",
      "    -x PREFIX, --prefix=PREFIX\r\n",
      "                        Add this prefix to read names. Use {name} to insert\r\n",
      "                        the name of the matching adapter.\r\n",
      "    -y SUFFIX, --suffix=SUFFIX\r\n",
      "                        Add this suffix to read names; can also include {name}\r\n",
      "\r\n",
      "  Filtering of processed reads:\r\n",
      "    Filters are applied after above read modifications. Paired-end reads\r\n",
      "    are always discarded pairwise (see also --pair-filter).\r\n",
      "\r\n",
      "    -m LENGTH, --minimum-length=LENGTH\r\n",
      "                        Discard reads shorter than LENGTH. Default: 0\r\n",
      "    -M LENGTH, --maximum-length=LENGTH\r\n",
      "                        Discard reads longer than LENGTH. Default: no limit\r\n",
      "    --max-n=COUNT       Discard reads with more than COUNT 'N' bases. If COUNT\r\n",
      "                        is a number between 0 and 1, it is interpreted as a\r\n",
      "                        fraction of the read length.\r\n",
      "    --discard-trimmed, --discard\r\n",
      "                        Discard reads that contain an adapter. Also use -O to\r\n",
      "                        avoid discarding too many randomly matching reads!\r\n",
      "    --discard-untrimmed, --trimmed-only\r\n",
      "                        Discard reads that do not contain an adapter.\r\n",
      "    --discard-casava    Discard reads that did not pass CASAVA filtering\r\n",
      "                        (header has :Y:).\r\n",
      "\r\n",
      "  Output:\r\n",
      "    --quiet             Print only error messages.\r\n",
      "    -o FILE, --output=FILE\r\n",
      "                        Write trimmed reads to FILE. FASTQ or FASTA format is\r\n",
      "                        chosen depending on input. The summary report is sent\r\n",
      "                        to standard output. Use '{name}' in FILE to\r\n",
      "                        demultiplex reads into multiple files. Default: write\r\n",
      "                        to standard output\r\n",
      "    --info-file=FILE    Write information about each read and its adapter\r\n",
      "                        matches into FILE. See the documentation for the file\r\n",
      "                        format.\r\n",
      "    -r FILE, --rest-file=FILE\r\n",
      "                        When the adapter matches in the middle of a read,\r\n",
      "                        write the rest (after the adapter) to FILE.\r\n",
      "    --wildcard-file=FILE\r\n",
      "                        When the adapter has N wildcard bases, write adapter\r\n",
      "                        bases matching wildcard positions to FILE. (Inaccurate\r\n",
      "                        with indels.)\r\n",
      "    --too-short-output=FILE\r\n",
      "                        Write reads that are too short (according to length\r\n",
      "                        specified by -m) to FILE. Default: discard reads\r\n",
      "    --too-long-output=FILE\r\n",
      "                        Write reads that are too long (according to length\r\n",
      "                        specified by -M) to FILE. Default: discard reads\r\n",
      "    --untrimmed-output=FILE\r\n",
      "                        Write reads that do not contain any adapter to FILE.\r\n",
      "                        Default: output to same file as trimmed reads\r\n",
      "\r\n",
      "  Colorspace options:\r\n",
      "    -c, --colorspace    Enable colorspace mode\r\n",
      "    -d, --double-encode\r\n",
      "                        Double-encode colors (map 0,1,2,3,4 to A,C,G,T,N).\r\n",
      "    -t, --trim-primer   Trim primer base and the first color\r\n",
      "    --strip-f3          Strip the _F3 suffix of read names\r\n",
      "    --maq, --bwa        MAQ- and BWA-compatible colorspace output. This\r\n",
      "                        enables -c, -d, -t, --strip-f3 and -y '/1'.\r\n",
      "    -z, --zero-cap      Change negative quality values to zero. Enabled by\r\n",
      "                        default in colorspace mode since many tools have\r\n",
      "                        problems with negative qualities\r\n",
      "    --no-zero-cap       Disable zero capping\r\n",
      "\r\n",
      "  Paired-end options:\r\n",
      "    The -A/-G/-B/-U options work like their -a/-b/-g/-u counterparts, but\r\n",
      "    are applied to the second read in each pair.\r\n",
      "\r\n",
      "    -A ADAPTER          3' adapter to be removed from second read in a pair.\r\n",
      "    -G ADAPTER          5' adapter to be removed from second read in a pair.\r\n",
      "    -B ADAPTER          5'/3 adapter to be removed from second read in a pair.\r\n",
      "    -U LENGTH           Remove LENGTH bases from second read in a pair.\r\n",
      "    -p FILE, --paired-output=FILE\r\n",
      "                        Write second read in a pair to FILE.\r\n",
      "    --pair-filter=(any|both)\r\n",
      "                        Which of the reads in a paired-end read have to match\r\n",
      "                        the filtering criterion in order for the pair to be\r\n",
      "                        filtered. Default: any\r\n",
      "    --interleaved       Read and write interleaved paired-end reads.\r\n",
      "    --untrimmed-paired-output=FILE\r\n",
      "                        Write second read in a pair to this FILE when no\r\n",
      "                        adapter was found. Use with --untrimmed-output.\r\n",
      "                        Default: output to same file as trimmed reads\r\n",
      "    --too-short-paired-output=FILE\r\n",
      "                        Write second read in a pair to this file if pair is\r\n",
      "                        too short. Use also --too-short-output.\r\n",
      "    --too-long-paired-output=FILE\r\n",
      "                        Write second read in a pair to this file if pair is\r\n",
      "                        too long. Use also --too-long-output.\r\n"
     ]
    }
   ],
   "source": [
    "!cutadapt --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">M02215:3:000000000-B9JT7:1:1101:16057:1914 1:N:0:1\r\n",
      "CGTGCAGTGGGTACTGGTTGAACAGTTTACCCTCCTAGCCGGAAACCTAGCCCACGCCGGGCCATCCGTAGATTTAACTATCTTCTCTCTACACTTAGCCGGAGTATCTTCCATCCTCGGAGCAATTAACTTTATTACAACAGCAATCAACATAAAACCCCCAGCAATATCCCAATACCAAACACCACTATTTGTGTGATCCGTCCTAATTACAGCTGTACTTCTCCTACTATCCCTACCAGTACTAGCTGCTGGAATTACAATACTACACACAGACCGCAACTTAAACACAACCTTCTTTGACCCCGCAGGGGGAGGAGATCCCATCCTATACCAACACCTCTTCTGATTCTTCGGCA\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:12015:1916 1:N:0:1\r\n",
      "GCGATATCGTAGACCTCGGGATGGCCAAAAAATCAGAAAAGGTGTTGGTATAAAACTGGATCACCACCTCCTGAAGGATCAAAGAAAGTAGTATTGAAATTACGATCACAAAGTAACATAGTTATCGCACCGGCCAAAACAGGTAAAGACAACAATAAAAGAAAAGCTGTAATTAAAACAGCCCACACAAATAAAGGTACTCTATGCATTGTCATACCTGGACATCGCATATTAAAAATTGTAGTTATGAAATTTACAGCACCTAAGATCGACGATGCACCTGAAACATGGAGACTGAAGATCGCTAAATCTACGGCACCACCAGGGTGAGCCATCGTACTACTTAAAGGGGGGTATACAGTTCATCCTGTTCCCGATATTTG\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:12197:1916 1:N:0:1\r\n",
      "CTTGTCTCTTAGACCTCGGGGTGGCCAAAAAATCAAAAAAGATGCTGGTATAAAACGGGATCACCTCCACCTGCTGGATCAAAGAAAGCAGTATTGAAGTTTCGATCGGTTAATAGCATAGTAATCGCTCCTGCTAAAACAGGTAACGATAATAATAATAAAAATGCAGTAATTAAAACTGCCCAAACGAAAAGAGGAAGTCGGTGCATGGTTAAACCAGGTGCACGCATGTTAAAAATAGTAGTAATAAAATTAATTGCTCCTAAAATTGAAGACGCACCAGAAAGGTGTAAACTAAAAATAGCTAAATCAACAGATGGACCTGAGTGTGCTTGTACACTTGAAAGAGGGGGATAAACAGTTCATCCTGTACCAGAGACCCA\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:15055:1921 1:N:0:1\r\n",
      "GGCACGACGGGAACTGGTTGAACTGTTTACCCCCCTTATCTAGAAACATTGCCCATGCAAGCCCAGCAGTTGACATAGCAATTTTCTCACTGCACCTAGCAGGAGCATCTTCAGTAATTGCCTCAATCAACTTTATAACAACAATTTATAACATGCGCAATGAGGGCTACACCATAGAACGTGTCCCCCTATTTGTCTGATCAATCATAATTACTTCTGGCCTACTTGTGCTGGCAATCCCAGTTCTCGCAGCAGGAATTACTATACTACTAACAGACCGAAATCTAAATACCACATTCTTCGACCCTGTCGGAGGGGGAGACCATGTTTTATACCAACACCTCTTCTGGTTTTTTGGCCACCCCGAGGTCTACGTCGTTA\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:15854:1924 1:N:0:1\r\n",
      "TCTGGAACTGGTTGAACAGTATATCCCCCGTTAAGTAGTGTAACTTCTCACTCTGGAGGATCTGTAGACTTAGCTATCTTTAGTTTACACTTATCAGGATTAAGTAGTCTTTTAGGAGCTATCAACTTTATTACAGCCATATTTAACATGAGAGGTCCTGGAATGACTATGCATAGACTTCCATTATTTGTTTGGTCAGTCTTAATAACTGCATTTCTGCTTTTATTATCACTTCCTGTTTTAGCAGGTGCTATTACAATGTTACTTACGGATCGTAACTTTAATACTAGTTTCTTTGACCCTGCAGGTGGAGGAGATCCAATACTTTTTCAACACCTTTTTTGATTCTTCGGCCACCCCGAAGTCTAAGAGACGTA\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/FASTA/Lib-1.assembled.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -g file:/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/FASTA/metadatatags.fasta -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sample{name}.fasta /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/FASTA/Lib-1.assembled.fasta\n",
      "Running on 1 core\n",
      "Trimming 15 adapters with at most 10.0% errors in single-end mode ...\n",
      "Finished in 302.88 s (164 us/read; 0.37 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:               1,844,518\n",
      "Reads with adapters:                 1,634,710 (88.6%)\n",
      "Reads written (passing filters):     1,844,518 (100.0%)\n",
      "\n",
      "Total basepairs processed:   703,696,897 bp\n",
      "Total written (filtered):    688,984,507 bp (97.9%)\n",
      "\n",
      "=== Adapter CTCGCA ===\n",
      "\n",
      "Sequence: NNNCTCGCA; Type: anchored 5'; Length: 9; Trimmed: 117215 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t117215\t7.0\t0\t117215\n",
      "\n",
      "=== Adapter ATCAGT ===\n",
      "\n",
      "Sequence: NNNATCAGT; Type: anchored 5'; Length: 9; Trimmed: 234 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t234\t7.0\t0\t234\n",
      "\n",
      "=== Adapter TCGCAT ===\n",
      "\n",
      "Sequence: NNNTCGCAT; Type: anchored 5'; Length: 9; Trimmed: 117649 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t117649\t7.0\t0\t117649\n",
      "\n",
      "=== Adapter ACAGCA ===\n",
      "\n",
      "Sequence: NNNACAGCA; Type: anchored 5'; Length: 9; Trimmed: 105497 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t105497\t7.0\t0\t105497\n",
      "\n",
      "=== Adapter ATATCG ===\n",
      "\n",
      "Sequence: NNNATATCG; Type: anchored 5'; Length: 9; Trimmed: 94944 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t94944\t7.0\t0\t94944\n",
      "\n",
      "=== Adapter GATGAC ===\n",
      "\n",
      "Sequence: NNNGATGAC; Type: anchored 5'; Length: 9; Trimmed: 101433 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t101433\t7.0\t0\t101433\n",
      "\n",
      "=== Adapter ACATGT ===\n",
      "\n",
      "Sequence: NNNACATGT; Type: anchored 5'; Length: 9; Trimmed: 84469 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t84469\t7.0\t0\t84469\n",
      "\n",
      "=== Adapter ACGACG ===\n",
      "\n",
      "Sequence: NNNACGACG; Type: anchored 5'; Length: 9; Trimmed: 115183 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t115183\t7.0\t0\t115183\n",
      "\n",
      "=== Adapter ACACAC ===\n",
      "\n",
      "Sequence: NNNACACAC; Type: anchored 5'; Length: 9; Trimmed: 100481 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t100481\t7.0\t0\t100481\n",
      "\n",
      "=== Adapter GCAGTG ===\n",
      "\n",
      "Sequence: NNNGCAGTG; Type: anchored 5'; Length: 9; Trimmed: 109504 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t109504\t7.0\t0\t109504\n",
      "\n",
      "=== Adapter TGTATG ===\n",
      "\n",
      "Sequence: NNNTGTATG; Type: anchored 5'; Length: 9; Trimmed: 140882 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t140882\t7.0\t0\t140882\n",
      "\n",
      "=== Adapter CGACGC ===\n",
      "\n",
      "Sequence: NNNCGACGC; Type: anchored 5'; Length: 9; Trimmed: 156487 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t156487\t7.0\t0\t156487\n",
      "\n",
      "=== Adapter TCGTCA ===\n",
      "\n",
      "Sequence: NNNTCGTCA; Type: anchored 5'; Length: 9; Trimmed: 105449 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t105449\t7.0\t0\t105449\n",
      "\n",
      "=== Adapter GTCTCT ===\n",
      "\n",
      "Sequence: NNNGTCTCT; Type: anchored 5'; Length: 9; Trimmed: 174610 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t174610\t7.0\t0\t174610\n",
      "\n",
      "=== Adapter GCGCTC ===\n",
      "\n",
      "Sequence: NNNGCGCTC; Type: anchored 5'; Length: 9; Trimmed: 110673 times.\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "9\t110673\t7.0\t0\t110673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cutadapt \\\n",
    "-g file:/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/FASTA/metadatatags.fasta \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sample{name}.fasta \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/FASTA/Lib-1.assembled.fasta \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove forward and reverse primers from the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACA.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACACAC.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 4.75 s (47 us/read; 1.27 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 100,481\n",
      "Reads with adapters:                    60,096 (59.8%)\n",
      "Reads written (passing filters):        60,096 (59.8%)\n",
      "\n",
      "Total basepairs processed:    37,471,976 bp\n",
      "Total written (filtered):     20,825,293 bp (55.6%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 60096 times; 3' trimmed: 6625 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t53\t0.0\t2\t0 0 53\n",
      "25\t966\t0.0\t2\t0 948 18\n",
      "26\t58881\t0.0\t2\t58359 515 7\n",
      "27\t123\t0.0\t2\t0 119 4\n",
      "28\t73\t0.0\t2\t0 0 73\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3168\t1570.0\t0\t3168\n",
      "4\t3405\t392.5\t0\t3405\n",
      "5\t3\t98.1\t0\t3\n",
      "6\t13\t24.5\t0\t13\n",
      "7\t17\t6.1\t0\t17\n",
      "11\t6\t0.0\t1\t0 6\n",
      "22\t1\t0.0\t2\t1\n",
      "66\t10\t0.0\t2\t8 2\n",
      "367\t1\t0.0\t2\t1\n",
      "374\t1\t0.0\t2\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is done on only one of the Demultiplexed files\n",
    "!cutadapt \\\n",
    "-a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA \\ #Forward...Reverse\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACA.fasta --discard-untrimmed \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACACAC.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">M02215:3:000000000-B9JT7:1:1101:17642:1981 1:N:0:1\r\n",
      "TCTCTCAAGTAATGTTGCACATGCGGGAAGATCGGTTGACTTTGCCATTTTCTCATTACATTTGGCGGGAGTTAGTTCTATTTTAGGAGCTGTTAATTTTATTAGTACCCTTGGTAATTTACGTGTATTTGGTATAATTCTTGACCGAATGCCTCTATTTGCATGGTCTGTTCTGATTACCGCAGTATTACTATTGTTGTCTTTACCTGTGTTAGCCGGTGCCATTACTATACTTCTAACTGATCGAAACCTTAATTCTTCTTTTTATGATACTGGGGGAGGCGGGGATCCAATTTTATATCAACATTTATTCTGATTCTTCGGCCACCCCGAAGTCTAGTGTGT\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:14711:2016 1:N:0:1\r\n",
      "GTTAAGAAGAAACATTGCCCATGGGGGTGCATCTGTAGATCTCGCTATTTTCTCATTACACTTAGCGGGTGTATCCTCTTTACTAGGAGCGGTTAACTTTATTAGCACCCTAAGAAATTTACGTGCCATAGGAATGTTAATAGACCGAATGCCCTTGTTTCCATGAGCGGTGCTTGTAACTGCCGTACTACTACTACTATCTCTGCCAGTACTAGCTGGGGCTATCACAATGCTTCTAACAGATCGTAACTTTAACTCTTCTTTTTACGACCCTAGGGGAGGAGGGGACCCCTTACTCTACCAACATCTATTTTGGTTCTTCGGCCATCCCGAGGTCTAGTGTG\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:15762:2038 1:N:0:1\r\n",
      "TTTGTCAGGAATTTTAGCTCATTCTGGCGGCGCTGTCGATTTAGCTATTTTTAGCTTACATTTGGCGGGTATTTCGTCTATTTTAGGAGCTATAAATTTTATTGTAACTATTTTAAACATGCGTTGTCCTGGTATGACTGCTCATAGAACACCTTTATTTGTTTGGGCTGTTTTTATAACAGCTTTTTTACTTTTGTTATCACTTCCTGTTTTAGCTGGCGCTATTACAATGTTATTAACAGATAGAAATTTTAATACGTCTTTCTTTGATCCAAACGGTGGTGGTGATCCTGTCTTATATCAGCATTTGTTTTGATTCTTCGGCCACCCCGAAGTCTAGTGTGTGAT\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:20111:2054 1:N:0:1\r\n",
      "CTTATCTAGAAACATTGCCCATGCAAGCCCAGCAGTTGACATAGCAATTTTCTCACTGCACCTAGCAGGAGCATCTTCAGTAATTGCCTCAATCAACTTTATAACAACAATTTATAACATGCGCAATGAGGGCTACACCATAGAACGTGTCCCCCTATTTGTCTGATCAATCATAATTACTTCTGGCCTACTTGTGCTGGCAATCCCAGTTCTCGCAGCAGGAATTACTATACTACTAACAGACCGAAATCTAAATACCACATTCTTCGACCCTGTCGGAGGGGGAGACCCTGTTTTATACCAACACCTCTTCTGATTCTTCGGCCACCCCGAAGTCTAGTGTGTCCA\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:15426:2127 1:N:0:1\r\n",
      "TCTAAGTCATATTACGAGCCACTCTGGTGGTGCAGTTGATTTAGCTATTTTCAGTTTACATTTATCTGGAGCGAGCAGTATTTTAGGGGCGATTAACTTTATTACCACTATCTTTAACATGCGTGGGCCTGGTCTGGGCTTCCATCGCTTACCTTTATTTGTGTGGTCTGTTCTGATTACGGCCTTCTTACTTCTTCTCTCTTTACCTGTTTTAGCGGGAGCGATTACGATGCTGTTAACGGATCGTAACTTCAATACCTCGTTCTTTGATCCGGCGGGCGGAGGTGACCCTATTTTGTTCCAGCACCTTTTTTGGTTTTTCGGCCATCCCGAAGTCTAGTGTGTAGG\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACA.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempted For Looping\n",
    "!for file in /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/*.fasta ; do \\\n",
    "cutadapt \\\n",
    "-a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACA.fasta --discard-untrimmed \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACACAC.fasta\n",
    "${file} \\\n",
    "; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempted For Looping\n",
    "!for file in /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/*.fasta ; do \\\n",
    "basename \"${file}\" \\\n",
    "; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping only unique sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACA.fasta 100%       \n",
      "20825293 nt in 60096 seqs, min 50, max 454, avg 347\n",
      "Sorting 100%\n",
      "49436 unique sequences, avg cluster 1.2, median 1, max 42\n",
      "Writing output file 100%  \n",
      "4332 uniques written, 45104 clusters discarded (91.2%)\n"
     ]
    }
   ],
   "source": [
    "!vsearch \\\n",
    "--derep_fulllength /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACA.fasta \\\n",
    "--minuniquesize 2 \\\n",
    "--sizeout \\\n",
    "--output /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACACA.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">M02215:3:000000000-B9JT7:1:1101:14861:11376 1:N:0:1;size=42\r\n",
      "TCTAAGTCATATTACGAGCCACTCTGGTGGTGCAGTTGATTTAGCTATTTTCAGTTTACATTTATCTGGAGCGAGCAGTA\r\n",
      "TTTTAGGGGCGATTAACTTTATTACCACTATCTTTAACATGCGTGGGCCTGGTCTGGGCTTCCATCGCTTACCTTTATTT\r\n",
      "GTGTGGTCTGTTCTGATTACGGCCTTCTTACTTCTTCTCTCTTTACCGGTTTTAGCGGGAGCGATTACGATGCTGTTAAC\r\n",
      "GGATCGTAACTTCAATACCTCGTTCTTTGATCCGGCGGGCGGAGGTGACCCTATTTTGTTCCAGCACCTTTTTTGATTCT\r\n",
      "TCGGCCACCCCGAAGTCTAGTGTG\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:22049:15396 1:N:0:1;size=40\r\n",
      "TCTAAGTCATATTACGAGCCACTCTGGTGGTGCAGTTGATTTAGCTATTTTCAGTTTACATTTATCTGGAGCGAGCAGTA\r\n",
      "TTTTAGGGGCGATTAACTTTATTACCACTATCTTTAACATGCGTGGGCCTGGTCTGGGCTTCCATCGCTTACCTTTATTT\r\n",
      "GTGTGGTCTGTTCTGATTACGGCCTTCTTACTTCTTCTCTCTTTACCGGTTTTAGCGGGAGCGATTACGATGCTGTTAAC\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACACA.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\r\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\r\n",
      "https://github.com/torognes/swarm\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\r\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\r\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\r\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\r\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\r\n",
      "\r\n",
      "Usage: swarm [OPTIONS] [FASTAFILE]\r\n",
      "\r\n",
      "General options:\r\n",
      " -h, --help                          display this help and exit\r\n",
      " -t, --threads INTEGER               number of threads to use (1)\r\n",
      " -v, --version                       display version information and exit\r\n",
      "\r\n",
      "Clustering options:\r\n",
      " -d, --differences INTEGER           resolution (1)\r\n",
      " -n, --no-otu-breaking               never break OTUs (not recommended!)\r\n",
      "\r\n",
      "Fastidious options (only when d = 1):\r\n",
      " -b, --boundary INTEGER              min mass of large OTU for fastidious (3)\r\n",
      " -c, --ceiling INTEGER               max memory in MB used for fastidious\r\n",
      " -f, --fastidious                    link nearby low-abundance swarms\r\n",
      " -y, --bloom-bits INTEGER            bits used per Bloom filter entry (16)\r\n",
      "\r\n",
      "Input/output options:\r\n",
      " -a, --append-abundance INTEGER      value to use when abundance is missing\r\n",
      " -i, --internal-structure FILENAME   write internal swarm structure to file\r\n",
      " -l, --log FILENAME                  log to file, not to stderr\r\n",
      " -o, --output-file FILENAME          output result filename (stdout)\r\n",
      " -r, --mothur                        output in mothur list file format\r\n",
      " -s, --statistics-file FILENAME      dump OTU statistics to file\r\n",
      " -u, --uclust-file FILENAME          output in UCLUST-like format to file\r\n",
      " -w, --seeds FILENAME                write seed seqs with abundances to FASTA\r\n",
      " -z, --usearch-abundance             abundance annotation in usearch style\r\n",
      "\r\n",
      "Pairwise alignment advanced options (only when d > 1):\r\n",
      " -m, --match-reward INTEGER          reward for nucleotide match (5)\r\n",
      " -p, --mismatch-penalty INTEGER      penalty for nucleotide mismatch (4)\r\n",
      " -g, --gap-opening-penalty INTEGER   gap open penalty (12)\r\n",
      " -e, --gap-extension-penalty INTEGER gap extension penalty (4)\r\n",
      "\r\n",
      "See 'man swarm' for more details.\r\n"
     ]
    }
   ],
   "source": [
    "!swarm --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACACA.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/sampleACACA.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%  \n",
      "\n",
      "Error: Abundance annotations not found for 4332 sequences, starting on line 1.\n",
      ">M02215:3:000000000-B9JT7:1:1101:14861:11376\n",
      "Fasta headers must end with abundance annotations (_INT or ;size=INT).\n",
      "The -z option must be used if the abundance annotation is in the latter format.\n",
      "Abundance annotations can be produced by dereplicating the sequences.\n",
      "The header is defined as the string comprised between the \">\" symbol\n",
      "and the first space or the end of the line, whichever comes first.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Doesn't like spaces\n",
    "!swarm \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/sampleACACA.txt \\\n",
    "-z \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACACA.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to remove all white spaces from the fasta file\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACACA.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/RemsampleACACA.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTTTAGGAGCTGTTAATTTTATTAGTACCCTTGGTAATTTACGTGTATTTGGTATAATTCTTGACCGAATGCCCCTATTT\r\n",
      "GCATGGTCTGTTCTGATTACCGCAGTATTACTATTGTTGTCTTTACCTGTGTTAGCCGGTGCCATTACTATACTTCTAAC\r\n",
      "TGATCGAAACCTTAATTCTTCTTTTTATGATACTAGGGGAGGCGGGGATCCAATTTTATATCAACATTTATTCTGGTTCT\r\n",
      "TTGGCCATCCCGAAGTCTAGTGT\r\n",
      ">M02215:3:000000000-B9JT7:1:2114:8846:109011:N:0:1;size=2\r\n",
      "TTTAAGTAGTACGATGGCTCATCCTGGTGGTGCCGTAGATTTAGCGATCTTCAGTCTCCATGTTTCAGGTGCATCGTCGA\r\n",
      "TCTTAGGTGCTGTAAATTTCATAACTACAATTTTTAATATGCGATGTCCAGGTATGACAATGCATAGAGTACCTTTATTT\r\n",
      "GTGTGGGCTGTTTTAATTACAGCTTTTCTTTTATTGTTGTCTTTACCTGTTTTGGCCGGTGCGATAACTATGTTACTTTG\r\n",
      "TGATCGTAATTTCAATACTACTTTCTTTGATCCTTCAGGAGGTGGTGATCCAGTTTTATACCAACACCTTTTCTGATTCT\r\n",
      "TCGGCCACCCCGAGGTCTAGTGTGT\r\n"
     ]
    }
   ],
   "source": [
    "!tail /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/RemsampleACACA.fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\r\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\r\n",
      "https://github.com/torognes/swarm\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\r\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\r\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\r\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\r\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\r\n",
      "\r\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\r\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/RemsampleACACA.fasta\r\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/sampleACACA.txt\r\n",
      "Resolution (d):    1\r\n",
      "Threads:           1\r\n",
      "Break OTUs:        Yes\r\n",
      "Fastidious:        No\r\n",
      "\r\n",
      "Reading database:  0%  \r",
      "Reading database:  0%  \r",
      "Reading database:  1%  \r",
      "Reading database:  1%  \r",
      "Reading database:  2%  \r",
      "Reading database:  2%  \r",
      "Reading database:  3%  \r",
      "Reading database:  3%  \r",
      "Reading database:  4%  \r",
      "Reading database:  4%  \r",
      "Reading database:  5%  \r",
      "Reading database:  5%  \r",
      "Reading database:  6%  \r",
      "Reading database:  6%  \r",
      "Reading database:  7%  \r",
      "Reading database:  7%  \r",
      "Reading database:  8%  \r",
      "Reading database:  8%  \r",
      "Reading database:  9%  \r",
      "Reading database:  9%  \r",
      "Reading database:  10%  \r",
      "Reading database:  10%  \r",
      "Reading database:  11%  \r",
      "Reading database:  11%  \r",
      "Reading database:  12%  \r",
      "Reading database:  12%  \r",
      "Reading database:  13%  \r",
      "Reading database:  13%  \r",
      "Reading database:  14%  \r",
      "Reading database:  14%  \r",
      "Reading database:  15%  \r",
      "Reading database:  15%  \r",
      "Reading database:  16%  \r",
      "Reading database:  16%  \r",
      "Reading database:  17%  \r",
      "Reading database:  17%  \r",
      "Reading database:  18%  \r",
      "Reading database:  18%  \r",
      "Reading database:  19%  \r",
      "Reading database:  19%  \r",
      "Reading database:  20%  \r",
      "Reading database:  20%  \r",
      "Reading database:  21%  \r",
      "Reading database:  21%  \r",
      "Reading database:  22%  \r",
      "Reading database:  22%  \r",
      "Reading database:  23%  \r",
      "Reading database:  23%  \r",
      "Reading database:  24%  \r",
      "Reading database:  24%  \r",
      "Reading database:  25%  \r",
      "Reading database:  25%  \r",
      "Reading database:  26%  \r",
      "Reading database:  26%  \r",
      "Reading database:  27%  \r",
      "Reading database:  27%  \r",
      "Reading database:  28%  \r",
      "Reading database:  28%  \r",
      "Reading database:  29%  \r",
      "Reading database:  29%  \r",
      "Reading database:  30%  \r",
      "Reading database:  31%  \r",
      "Reading database:  31%  \r",
      "Reading database:  32%  \r",
      "Reading database:  32%  \r",
      "Reading database:  33%  \r",
      "Reading database:  33%  \r",
      "Reading database:  34%  \r",
      "Reading database:  34%  \r",
      "Reading database:  35%  \r",
      "Reading database:  35%  \r",
      "Reading database:  36%  \r",
      "Reading database:  36%  \r",
      "Reading database:  37%  \r",
      "Reading database:  37%  \r",
      "Reading database:  38%  \r",
      "Reading database:  38%  \r",
      "Reading database:  39%  \r",
      "Reading database:  39%  \r",
      "Reading database:  40%  \r",
      "Reading database:  40%  \r",
      "Reading database:  41%  \r",
      "Reading database:  41%  \r",
      "Reading database:  42%  \r",
      "Reading database:  42%  \r",
      "Reading database:  43%  \r",
      "Reading database:  43%  \r",
      "Reading database:  44%  \r",
      "Reading database:  44%  \r",
      "Reading database:  45%  \r",
      "Reading database:  45%  \r",
      "Reading database:  46%  \r",
      "Reading database:  46%  \r",
      "Reading database:  47%  \r",
      "Reading database:  47%  \r",
      "Reading database:  48%  \r",
      "Reading database:  48%  \r",
      "Reading database:  49%  \r",
      "Reading database:  49%  \r",
      "Reading database:  50%  \r",
      "Reading database:  50%  \r",
      "Reading database:  51%  \r",
      "Reading database:  51%  \r",
      "Reading database:  52%  \r",
      "Reading database:  52%  \r",
      "Reading database:  53%  \r",
      "Reading database:  53%  \r",
      "Reading database:  54%  \r",
      "Reading database:  54%  \r",
      "Reading database:  55%  \r",
      "Reading database:  55%  \r",
      "Reading database:  56%  \r",
      "Reading database:  56%  \r",
      "Reading database:  57%  \r",
      "Reading database:  57%  \r",
      "Reading database:  58%  \r",
      "Reading database:  58%  \r",
      "Reading database:  59%  \r",
      "Reading database:  59%  \r",
      "Reading database:  60%  \r",
      "Reading database:  60%  \r",
      "Reading database:  61%  \r",
      "Reading database:  61%  \r",
      "Reading database:  62%  \r",
      "Reading database:  63%  \r",
      "Reading database:  63%  \r",
      "Reading database:  64%  \r",
      "Reading database:  64%  \r",
      "Reading database:  65%  \r",
      "Reading database:  65%  \r",
      "Reading database:  66%  \r",
      "Reading database:  66%  \r",
      "Reading database:  67%  \r",
      "Reading database:  67%  \r",
      "Reading database:  68%  \r",
      "Reading database:  68%  \r",
      "Reading database:  69%  \r",
      "Reading database:  69%  \r",
      "Reading database:  70%  \r",
      "Reading database:  70%  \r",
      "Reading database:  71%  \r",
      "Reading database:  71%  \r",
      "Reading database:  72%  \r",
      "Reading database:  72%  \r",
      "Reading database:  73%  \r",
      "Reading database:  73%  \r",
      "Reading database:  74%  \r",
      "Reading database:  74%  \r",
      "Reading database:  75%  \r",
      "Reading database:  75%  \r",
      "Reading database:  76%  \r",
      "Reading database:  76%  \r",
      "Reading database:  77%  \r",
      "Reading database:  77%  \r",
      "Reading database:  78%  \r",
      "Reading database:  78%  \r",
      "Reading database:  79%  \r",
      "Reading database:  79%  \r",
      "Reading database:  80%  \r",
      "Reading database:  80%  \r",
      "Reading database:  81%  \r",
      "Reading database:  81%  \r",
      "Reading database:  82%  \r",
      "Reading database:  82%  \r",
      "Reading database:  83%  \r",
      "Reading database:  83%  \r",
      "Reading database:  84%  \r",
      "Reading database:  84%  \r",
      "Reading database:  85%  \r",
      "Reading database:  85%  \r",
      "Reading database:  86%  \r",
      "Reading database:  86%  \r",
      "Reading database:  87%  \r",
      "Reading database:  87%  \r",
      "Reading database:  88%  \r",
      "Reading database:  88%  \r",
      "Reading database:  89%  \r",
      "Reading database:  89%  \r",
      "Reading database:  90%  \r",
      "Reading database:  90%  \r",
      "Reading database:  91%  \r",
      "Reading database:  91%  \r",
      "Reading database:  92%  \r",
      "Reading database:  92%  \r",
      "Reading database:  93%  \r",
      "Reading database:  93%  \r",
      "Reading database:  94%  \r",
      "Reading database:  94%  \r",
      "Reading database:  95%  \r",
      "Reading database:  96%  \r",
      "Reading database:  96%  \r",
      "Reading database:  97%  \r",
      "Reading database:  97%  \r",
      "Reading database:  98%  \r",
      "Reading database:  98%  \r",
      "Reading database:  99%  \r",
      "Reading database:  99%  \r",
      "Reading database:  100%  \r",
      "Reading database:  100%\r\n",
      "Indexing database: 0%  \r",
      "Indexing database: 0%  \r",
      "Indexing database: 0%  \r",
      "Indexing database: 1%  \r",
      "Indexing database: 1%  \r",
      "Indexing database: 2%  \r",
      "Indexing database: 2%  \r",
      "Indexing database: 3%  \r",
      "Indexing database: 3%  \r",
      "Indexing database: 4%  \r",
      "Indexing database: 4%  \r",
      "Indexing database: 5%  \r",
      "Indexing database: 5%  \r",
      "Indexing database: 6%  \r",
      "Indexing database: 6%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 8%  \r",
      "Indexing database: 8%  \r",
      "Indexing database: 9%  \r",
      "Indexing database: 9%  \r",
      "Indexing database: 10%  \r",
      "Indexing database: 10%  \r",
      "Indexing database: 11%  \r",
      "Indexing database: 11%  \r",
      "Indexing database: 12%  \r",
      "Indexing database: 12%  \r",
      "Indexing database: 13%  \r",
      "Indexing database: 13%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 15%  \r",
      "Indexing database: 15%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 17%  \r",
      "Indexing database: 17%  \r",
      "Indexing database: 18%  \r",
      "Indexing database: 18%  \r",
      "Indexing database: 19%  \r",
      "Indexing database: 19%  \r",
      "Indexing database: 20%  \r",
      "Indexing database: 20%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 22%  \r",
      "Indexing database: 22%  \r",
      "Indexing database: 23%  \r",
      "Indexing database: 23%  \r",
      "Indexing database: 24%  \r",
      "Indexing database: 24%  \r",
      "Indexing database: 25%  \r",
      "Indexing database: 25%  \r",
      "Indexing database: 26%  \r",
      "Indexing database: 26%  \r",
      "Indexing database: 27%  \r",
      "Indexing database: 27%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 29%  \r",
      "Indexing database: 29%  \r",
      "Indexing database: 30%  \r",
      "Indexing database: 30%  \r",
      "Indexing database: 31%  \r",
      "Indexing database: 31%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 33%  \r",
      "Indexing database: 33%  \r",
      "Indexing database: 34%  \r",
      "Indexing database: 34%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 36%  \r",
      "Indexing database: 36%  \r",
      "Indexing database: 37%  \r",
      "Indexing database: 37%  \r",
      "Indexing database: 38%  \r",
      "Indexing database: 38%  \r",
      "Indexing database: 39%  \r",
      "Indexing database: 39%  \r",
      "Indexing database: 40%  \r",
      "Indexing database: 40%  \r",
      "Indexing database: 41%  \r",
      "Indexing database: 41%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 43%  \r",
      "Indexing database: 43%  \r",
      "Indexing database: 44%  \r",
      "Indexing database: 44%  \r",
      "Indexing database: 45%  \r",
      "Indexing database: 45%  \r",
      "Indexing database: 46%  \r",
      "Indexing database: 46%  \r",
      "Indexing database: 47%  \r",
      "Indexing database: 47%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 50%  \r",
      "Indexing database: 50%  \r",
      "Indexing database: 51%  \r",
      "Indexing database: 51%  \r",
      "Indexing database: 52%  \r",
      "Indexing database: 52%  \r",
      "Indexing database: 53%  \r",
      "Indexing database: 53%  \r",
      "Indexing database: 54%  \r",
      "Indexing database: 54%  \r",
      "Indexing database: 55%  \r",
      "Indexing database: 55%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 57%  \r",
      "Indexing database: 57%  \r",
      "Indexing database: 58%  \r",
      "Indexing database: 58%  \r",
      "Indexing database: 59%  \r",
      "Indexing database: 59%  \r",
      "Indexing database: 60%  \r",
      "Indexing database: 60%  \r",
      "Indexing database: 61%  \r",
      "Indexing database: 61%  \r",
      "Indexing database: 62%  \r",
      "Indexing database: 62%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 65%  \r",
      "Indexing database: 65%  \r",
      "Indexing database: 66%  \r",
      "Indexing database: 66%  \r",
      "Indexing database: 67%  \r",
      "Indexing database: 67%  \r",
      "Indexing database: 68%  \r",
      "Indexing database: 68%  \r",
      "Indexing database: 69%  \r",
      "Indexing database: 69%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 71%  \r",
      "Indexing database: 71%  \r",
      "Indexing database: 72%  \r",
      "Indexing database: 72%  \r",
      "Indexing database: 73%  \r",
      "Indexing database: 73%  \r",
      "Indexing database: 74%  \r",
      "Indexing database: 74%  \r",
      "Indexing database: 75%  \r",
      "Indexing database: 75%  \r",
      "Indexing database: 76%  \r",
      "Indexing database: 76%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 78%  \r",
      "Indexing database: 78%  \r",
      "Indexing database: 79%  \r",
      "Indexing database: 79%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 81%  \r",
      "Indexing database: 81%  \r",
      "Indexing database: 82%  \r",
      "Indexing database: 82%  \r",
      "Indexing database: 83%  \r",
      "Indexing database: 83%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 85%  \r",
      "Indexing database: 85%  \r",
      "Indexing database: 86%  \r",
      "Indexing database: 86%  \r",
      "Indexing database: 87%  \r",
      "Indexing database: 87%  \r",
      "Indexing database: 88%  \r",
      "Indexing database: 88%  \r",
      "Indexing database: 89%  \r",
      "Indexing database: 89%  \r",
      "Indexing database: 90%  \r",
      "Indexing database: 90%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 92%  \r",
      "Indexing database: 92%  \r",
      "Indexing database: 93%  \r",
      "Indexing database: 93%  \r",
      "Indexing database: 94%  \r",
      "Indexing database: 94%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 96%  \r",
      "Indexing database: 96%  \r",
      "Indexing database: 97%  \r",
      "Indexing database: 97%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 99%  \r",
      "Indexing database: 99%  \r",
      "Indexing database: 100%  \r",
      "Indexing database: 100%\r\n",
      "Database info:     1501897 nt in 4332 sequences, longest 351 nt\r\n",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 1%  \r",
      "Hashing sequences: 1%  \r",
      "Hashing sequences: 2%  \r",
      "Hashing sequences: 2%  \r",
      "Hashing sequences: 3%  \r",
      "Hashing sequences: 3%  \r",
      "Hashing sequences: 4%  \r",
      "Hashing sequences: 4%  \r",
      "Hashing sequences: 5%  \r",
      "Hashing sequences: 5%  \r",
      "Hashing sequences: 6%  \r",
      "Hashing sequences: 6%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 8%  \r",
      "Hashing sequences: 8%  \r",
      "Hashing sequences: 9%  \r",
      "Hashing sequences: 9%  \r",
      "Hashing sequences: 10%  \r",
      "Hashing sequences: 10%  \r",
      "Hashing sequences: 11%  \r",
      "Hashing sequences: 11%  \r",
      "Hashing sequences: 12%  \r",
      "Hashing sequences: 12%  \r",
      "Hashing sequences: 13%  \r",
      "Hashing sequences: 13%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 15%  \r",
      "Hashing sequences: 15%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 17%  \r",
      "Hashing sequences: 17%  \r",
      "Hashing sequences: 18%  \r",
      "Hashing sequences: 18%  \r",
      "Hashing sequences: 19%  \r",
      "Hashing sequences: 19%  \r",
      "Hashing sequences: 20%  \r",
      "Hashing sequences: 20%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 22%  \r",
      "Hashing sequences: 22%  \r",
      "Hashing sequences: 23%  \r",
      "Hashing sequences: 23%  \r",
      "Hashing sequences: 24%  \r",
      "Hashing sequences: 24%  \r",
      "Hashing sequences: 25%  \r",
      "Hashing sequences: 25%  \r",
      "Hashing sequences: 26%  \r",
      "Hashing sequences: 26%  \r",
      "Hashing sequences: 27%  \r",
      "Hashing sequences: 27%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 29%  \r",
      "Hashing sequences: 29%  \r",
      "Hashing sequences: 30%  \r",
      "Hashing sequences: 30%  \r",
      "Hashing sequences: 31%  \r",
      "Hashing sequences: 31%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 33%  \r",
      "Hashing sequences: 33%  \r",
      "Hashing sequences: 34%  \r",
      "Hashing sequences: 34%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 36%  \r",
      "Hashing sequences: 36%  \r",
      "Hashing sequences: 37%  \r",
      "Hashing sequences: 37%  \r",
      "Hashing sequences: 38%  \r",
      "Hashing sequences: 38%  \r",
      "Hashing sequences: 39%  \r",
      "Hashing sequences: 39%  \r",
      "Hashing sequences: 40%  \r",
      "Hashing sequences: 40%  \r",
      "Hashing sequences: 41%  \r",
      "Hashing sequences: 41%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 43%  \r",
      "Hashing sequences: 43%  \r",
      "Hashing sequences: 44%  \r",
      "Hashing sequences: 44%  \r",
      "Hashing sequences: 45%  \r",
      "Hashing sequences: 45%  \r",
      "Hashing sequences: 46%  \r",
      "Hashing sequences: 46%  \r",
      "Hashing sequences: 47%  \r",
      "Hashing sequences: 47%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 50%  \r",
      "Hashing sequences: 50%  \r",
      "Hashing sequences: 51%  \r",
      "Hashing sequences: 51%  \r",
      "Hashing sequences: 52%  \r",
      "Hashing sequences: 52%  \r",
      "Hashing sequences: 53%  \r",
      "Hashing sequences: 53%  \r",
      "Hashing sequences: 54%  \r",
      "Hashing sequences: 54%  \r",
      "Hashing sequences: 55%  \r",
      "Hashing sequences: 55%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 57%  \r",
      "Hashing sequences: 57%  \r",
      "Hashing sequences: 58%  \r",
      "Hashing sequences: 58%  \r",
      "Hashing sequences: 59%  \r",
      "Hashing sequences: 59%  \r",
      "Hashing sequences: 60%  \r",
      "Hashing sequences: 60%  \r",
      "Hashing sequences: 61%  \r",
      "Hashing sequences: 61%  \r",
      "Hashing sequences: 62%  \r",
      "Hashing sequences: 62%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 65%  \r",
      "Hashing sequences: 65%  \r",
      "Hashing sequences: 66%  \r",
      "Hashing sequences: 66%  \r",
      "Hashing sequences: 67%  \r",
      "Hashing sequences: 67%  \r",
      "Hashing sequences: 68%  \r",
      "Hashing sequences: 68%  \r",
      "Hashing sequences: 69%  \r",
      "Hashing sequences: 69%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 71%  \r",
      "Hashing sequences: 71%  \r",
      "Hashing sequences: 72%  \r",
      "Hashing sequences: 72%  \r",
      "Hashing sequences: 73%  \r",
      "Hashing sequences: 73%  \r",
      "Hashing sequences: 74%  \r",
      "Hashing sequences: 74%  \r",
      "Hashing sequences: 75%  \r",
      "Hashing sequences: 75%  \r",
      "Hashing sequences: 76%  \r",
      "Hashing sequences: 76%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 78%  \r",
      "Hashing sequences: 78%  \r",
      "Hashing sequences: 79%  \r",
      "Hashing sequences: 79%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 81%  \r",
      "Hashing sequences: 81%  \r",
      "Hashing sequences: 82%  \r",
      "Hashing sequences: 82%  \r",
      "Hashing sequences: 83%  \r",
      "Hashing sequences: 83%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 85%  \r",
      "Hashing sequences: 85%  \r",
      "Hashing sequences: 86%  \r",
      "Hashing sequences: 86%  \r",
      "Hashing sequences: 87%  \r",
      "Hashing sequences: 87%  \r",
      "Hashing sequences: 88%  \r",
      "Hashing sequences: 88%  \r",
      "Hashing sequences: 89%  \r",
      "Hashing sequences: 89%  \r",
      "Hashing sequences: 90%  \r",
      "Hashing sequences: 90%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 92%  \r",
      "Hashing sequences: 92%  \r",
      "Hashing sequences: 93%  \r",
      "Hashing sequences: 93%  \r",
      "Hashing sequences: 94%  \r",
      "Hashing sequences: 94%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 96%  \r",
      "Hashing sequences: 96%  \r",
      "Hashing sequences: 97%  \r",
      "Hashing sequences: 97%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 99%  \r",
      "Hashing sequences: 99%  \r",
      "Hashing sequences: 100%  \r",
      "Hashing sequences: 100%\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering:        100%                  \n",
      "Writing swarms:    100%  \n",
      "\n",
      "Number of swarms:  583\n",
      "Largest swarm:     1073\n",
      "Max generations:   21\n"
     ]
    }
   ],
   "source": [
    "!swarm \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/sampleACACA.txt \\\n",
    "-z \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/RemsampleACACA.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xargs: illegal option -- h\r\n",
      "usage: xargs [-0opt] [-E eofstr] [-I replstr [-R replacements]] [-J replstr]\r\n",
      "             [-L number] [-n number [-x]] [-P maxprocs] [-s size]\r\n",
      "             [utility [argument ...]]\r\n"
     ]
    }
   ],
   "source": [
    "!xargs -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACACAC.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACAGCA.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACATGT.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACGACG.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleATATCG.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleATCAGT.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleCGACGC.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleCTCGCA.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGATGAC.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGCAGTG.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGCGCTC.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGTCTCT.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleTCGCAT.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleTCGTCA.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleTGTATG.fasta\r\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleunknown.fasta\r\n"
     ]
    }
   ],
   "source": [
    "!find /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sample*.fasta \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now with the other 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACAC.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACACAC.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 5.18 s (52 us/read; 1.16 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 100,481\n",
      "Reads with adapters:                    60,096 (59.8%)\n",
      "Reads written (passing filters):        60,096 (59.8%)\n",
      "\n",
      "Total basepairs processed:    37,471,976 bp\n",
      "Total written (filtered):     20,825,293 bp (55.6%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 60096 times; 3' trimmed: 6625 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t53\t0.0\t2\t0 0 53\n",
      "25\t966\t0.0\t2\t0 948 18\n",
      "26\t58881\t0.0\t2\t58359 515 7\n",
      "27\t123\t0.0\t2\t0 119 4\n",
      "28\t73\t0.0\t2\t0 0 73\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3168\t1570.0\t0\t3168\n",
      "4\t3405\t392.5\t0\t3405\n",
      "5\t3\t98.1\t0\t3\n",
      "6\t13\t24.5\t0\t13\n",
      "7\t17\t6.1\t0\t17\n",
      "11\t6\t0.0\t1\t0 6\n",
      "22\t1\t0.0\t2\t1\n",
      "66\t10\t0.0\t2\t8 2\n",
      "367\t1\t0.0\t2\t1\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACAGCA.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACAGCA.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 5.80 s (55 us/read; 1.09 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 105,497\n",
      "Reads with adapters:                    63,353 (60.1%)\n",
      "Reads written (passing filters):        63,353 (60.1%)\n",
      "\n",
      "Total basepairs processed:    39,382,598 bp\n",
      "Total written (filtered):     21,974,071 bp (55.8%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 63353 times; 3' trimmed: 6718 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t31\t0.0\t2\t0 0 31\n",
      "25\t705\t0.0\t2\t0 693 12\n",
      "26\t62409\t0.0\t2\t61941 461 7\n",
      "27\t127\t0.0\t2\t0 126 1\n",
      "28\t81\t0.0\t2\t0 0 81\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3293\t1648.4\t0\t3293\n",
      "4\t3370\t412.1\t0\t3370\n",
      "5\t3\t103.0\t0\t3\n",
      "6\t14\t25.8\t0\t14\n",
      "7\t13\t6.4\t0\t13\n",
      "10\t5\t0.1\t1\t0 5\n",
      "11\t10\t0.0\t1\t0 10\n",
      "57\t1\t0.0\t2\t1\n",
      "63\t1\t0.0\t2\t1\n",
      "66\t5\t0.0\t2\t4 1\n",
      "67\t2\t0.0\t2\t0 2\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACATGT.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACATGT.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 3.91 s (46 us/read; 1.30 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                  84,469\n",
      "Reads with adapters:                    46,992 (55.6%)\n",
      "Reads written (passing filters):        46,992 (55.6%)\n",
      "\n",
      "Total basepairs processed:    31,499,082 bp\n",
      "Total written (filtered):     16,285,414 bp (51.7%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 46992 times; 3' trimmed: 5031 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t36\t0.0\t2\t0 0 36\n",
      "25\t705\t0.0\t2\t0 694 11\n",
      "26\t46153\t0.0\t2\t45760 383 10\n",
      "27\t73\t0.0\t2\t0 73\n",
      "28\t25\t0.0\t2\t0 0 25\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t2251\t1319.8\t0\t2251\n",
      "4\t2742\t330.0\t0\t2742\n",
      "5\t1\t82.5\t0\t1\n",
      "6\t10\t20.6\t0\t10\n",
      "7\t12\t5.2\t0\t12\n",
      "11\t3\t0.0\t1\t0 3\n",
      "54\t1\t0.0\t2\t1\n",
      "66\t6\t0.0\t2\t6\n",
      "67\t1\t0.0\t2\t1\n",
      "68\t1\t0.0\t2\t1\n",
      "285\t1\t0.0\t2\t1\n",
      "367\t1\t0.0\t2\t1\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACGACG.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleACGACG.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 5.57 s (48 us/read; 1.24 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 115,183\n",
      "Reads with adapters:                    65,094 (56.5%)\n",
      "Reads written (passing filters):        65,094 (56.5%)\n",
      "\n",
      "Total basepairs processed:    43,019,826 bp\n",
      "Total written (filtered):     22,589,797 bp (52.5%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 65094 times; 3' trimmed: 6726 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t26\t0.0\t2\t0 0 26\n",
      "25\t394\t0.0\t2\t0 388 6\n",
      "26\t64371\t0.0\t2\t63834 526 11\n",
      "27\t236\t0.0\t2\t0 233 3\n",
      "28\t67\t0.0\t2\t0 0 67\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3364\t1799.7\t0\t3364\n",
      "4\t3288\t449.9\t0\t3288\n",
      "5\t1\t112.5\t0\t1\n",
      "6\t17\t28.1\t0\t17\n",
      "7\t30\t7.0\t0\t30\n",
      "10\t1\t0.1\t1\t0 1\n",
      "11\t7\t0.0\t1\t0 7\n",
      "40\t1\t0.0\t2\t1\n",
      "46\t1\t0.0\t2\t1\n",
      "57\t1\t0.0\t2\t1\n",
      "65\t1\t0.0\t2\t0 1\n",
      "66\t4\t0.0\t2\t4\n",
      "67\t4\t0.0\t2\t4\n",
      "359\t1\t0.0\t2\t1\n",
      "373\t1\t0.0\t2\t1\n",
      "374\t4\t0.0\t2\t4\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleATATCG.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleATATCG.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 4.42 s (47 us/read; 1.29 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                  94,944\n",
      "Reads with adapters:                    55,745 (58.7%)\n",
      "Reads written (passing filters):        55,745 (58.7%)\n",
      "\n",
      "Total basepairs processed:    35,433,801 bp\n",
      "Total written (filtered):     19,318,540 bp (54.5%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 55745 times; 3' trimmed: 8576 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t38\t0.0\t2\t0 0 38\n",
      "25\t477\t0.0\t2\t0 469 8\n",
      "26\t55070\t0.0\t2\t54597 466 7\n",
      "27\t124\t0.0\t2\t0 124\n",
      "28\t36\t0.0\t2\t0 0 36\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3111\t1483.5\t0\t3111\n",
      "4\t3148\t370.9\t0\t3148\n",
      "5\t45\t92.7\t0\t45\n",
      "6\t2250\t23.2\t0\t2250\n",
      "7\t14\t5.8\t0\t14\n",
      "11\t2\t0.0\t1\t0 2\n",
      "66\t3\t0.0\t2\t3\n",
      "78\t1\t0.0\t2\t1\n",
      "80\t1\t0.0\t2\t1\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleATCAGT.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleATCAGT.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 0.02 s (82 us/read; 0.73 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                     234\n",
      "Reads with adapters:                       125 (53.4%)\n",
      "Reads written (passing filters):           125 (53.4%)\n",
      "\n",
      "Total basepairs processed:        87,490 bp\n",
      "Total written (filtered):         43,531 bp (49.8%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 125 times; 3' trimmed: 9 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "26\t125\t0.0\t2\t122 3\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t7\t3.7\t0\t7\n",
      "4\t2\t0.9\t0\t2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleCGACGC.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleCGACGC.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 6.99 s (45 us/read; 1.34 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 156,487\n",
      "Reads with adapters:                    86,088 (55.0%)\n",
      "Reads written (passing filters):        86,088 (55.0%)\n",
      "\n",
      "Total basepairs processed:    58,444,832 bp\n",
      "Total written (filtered):     29,897,382 bp (51.2%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 86088 times; 3' trimmed: 4224 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t51\t0.0\t2\t0 0 51\n",
      "25\t603\t0.0\t2\t0 591 12\n",
      "26\t85179\t0.0\t2\t84404 761 14\n",
      "27\t175\t0.0\t2\t0 174 1\n",
      "28\t80\t0.0\t2\t0 0 80\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t4023\t2445.1\t0\t4023\n",
      "4\t129\t611.3\t0\t129\n",
      "5\t6\t152.8\t0\t6\n",
      "6\t18\t38.2\t0\t18\n",
      "7\t26\t9.6\t0\t26\n",
      "11\t6\t0.0\t1\t0 6\n",
      "14\t1\t0.0\t1\t1\n",
      "17\t1\t0.0\t1\t1\n",
      "51\t1\t0.0\t2\t1\n",
      "65\t1\t0.0\t2\t1\n",
      "66\t10\t0.0\t2\t9 0 1\n",
      "67\t1\t0.0\t2\t0 1\n",
      "100\t1\t0.0\t2\t0 0 1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleCTCGCA.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleCTCGCA.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 5.57 s (48 us/read; 1.26 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 117,215\n",
      "Reads with adapters:                    68,393 (58.3%)\n",
      "Reads written (passing filters):        68,393 (58.3%)\n",
      "\n",
      "Total basepairs processed:    43,770,957 bp\n",
      "Total written (filtered):     23,725,887 bp (54.2%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 68393 times; 3' trimmed: 2954 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t33\t0.0\t2\t0 0 33\n",
      "25\t328\t0.0\t2\t0 322 6\n",
      "26\t67771\t0.0\t2\t67206 553 12\n",
      "27\t192\t0.0\t2\t0 190 2\n",
      "28\t69\t0.0\t2\t0 0 69\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t2760\t1831.5\t0\t2760\n",
      "4\t85\t457.9\t0\t85\n",
      "5\t3\t114.5\t0\t3\n",
      "6\t12\t28.6\t0\t12\n",
      "7\t17\t7.2\t0\t17\n",
      "11\t4\t0.0\t1\t0 4\n",
      "64\t1\t0.0\t2\t1\n",
      "66\t8\t0.0\t2\t7 0 1\n",
      "319\t1\t0.0\t2\t1\n",
      "335\t1\t0.0\t2\t1\n",
      "338\t2\t0.0\t2\t1 1\n",
      "359\t1\t0.0\t2\t1\n",
      "368\t1\t0.0\t2\t1\n",
      "369\t1\t0.0\t2\t0 1\n",
      "371\t3\t0.0\t2\t3\n",
      "373\t6\t0.0\t2\t6\n",
      "374\t47\t0.0\t2\t41 6\n",
      "377\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGATGAC.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGATGAC.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 7.86 s (78 us/read; 0.77 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 101,433\n",
      "Reads with adapters:                    62,870 (62.0%)\n",
      "Reads written (passing filters):        62,870 (62.0%)\n",
      "\n",
      "Total basepairs processed:    37,874,632 bp\n",
      "Total written (filtered):     21,820,153 bp (57.6%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 62870 times; 3' trimmed: 2948 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t17\t0.0\t2\t0 0 17\n",
      "25\t303\t0.0\t2\t0 300 3\n",
      "26\t62438\t0.0\t2\t61966 458 14\n",
      "27\t96\t0.0\t2\t0 94 2\n",
      "28\t16\t0.0\t2\t0 0 16\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t2816\t1584.9\t0\t2816\n",
      "4\t67\t396.2\t0\t67\n",
      "5\t7\t99.1\t0\t7\n",
      "6\t7\t24.8\t0\t7\n",
      "7\t10\t6.2\t0\t10\n",
      "10\t3\t0.1\t1\t0 3\n",
      "11\t8\t0.0\t1\t1 7\n",
      "62\t1\t0.0\t2\t1\n",
      "65\t1\t0.0\t2\t1\n",
      "66\t4\t0.0\t2\t4\n",
      "67\t1\t0.0\t2\t1\n",
      "78\t1\t0.0\t2\t0 0 1\n",
      "364\t1\t0.0\t2\t1\n",
      "371\t1\t0.0\t2\t1\n",
      "372\t2\t0.0\t2\t2\n",
      "373\t2\t0.0\t2\t2\n",
      "374\t15\t0.0\t2\t13 1 1\n",
      "375\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGCAGTG.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGCAGTG.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 5.26 s (48 us/read; 1.25 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 109,504\n",
      "Reads with adapters:                    66,438 (60.7%)\n",
      "Reads written (passing filters):        66,438 (60.7%)\n",
      "\n",
      "Total basepairs processed:    40,768,165 bp\n",
      "Total written (filtered):     22,947,601 bp (56.3%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 66438 times; 3' trimmed: 6585 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t19\t0.0\t2\t0 0 19\n",
      "25\t394\t0.0\t2\t0 380 14\n",
      "26\t65762\t0.0\t2\t64809 925 28\n",
      "27\t240\t0.0\t2\t0 226 14\n",
      "28\t23\t0.0\t2\t0 0 23\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t2720\t1711.0\t0\t2720\n",
      "4\t128\t427.8\t0\t128\n",
      "5\t276\t106.9\t0\t276\n",
      "6\t321\t26.7\t0\t321\n",
      "7\t8\t6.7\t0\t8\n",
      "10\t182\t0.1\t1\t0 182\n",
      "11\t2937\t0.0\t1\t0 2937\n",
      "12\t1\t0.0\t1\t0 1\n",
      "51\t1\t0.0\t2\t1\n",
      "65\t1\t0.0\t2\t0 1\n",
      "66\t6\t0.0\t2\t5 0 1\n",
      "67\t2\t0.0\t2\t2\n",
      "373\t1\t0.0\t2\t0 1\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGCGCTC.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGCGCTC.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 6.13 s (55 us/read; 1.08 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 110,673\n",
      "Reads with adapters:                    62,728 (56.7%)\n",
      "Reads written (passing filters):        62,728 (56.7%)\n",
      "\n",
      "Total basepairs processed:    41,343,507 bp\n",
      "Total written (filtered):     21,795,369 bp (52.7%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 62728 times; 3' trimmed: 2931 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t67\t0.0\t2\t0 0 67\n",
      "25\t1159\t0.0\t2\t0 1146 13\n",
      "26\t61298\t0.0\t2\t60773 514 11\n",
      "27\t156\t0.0\t2\t0 151 5\n",
      "28\t48\t0.0\t2\t0 0 48\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t2789\t1729.3\t0\t2789\n",
      "4\t95\t432.3\t0\t95\n",
      "5\t1\t108.1\t0\t1\n",
      "6\t12\t27.0\t0\t12\n",
      "7\t17\t6.8\t0\t17\n",
      "11\t12\t0.0\t1\t0 12\n",
      "66\t4\t0.0\t2\t3 0 1\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGTCTCT.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleGTCTCT.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 8.88 s (51 us/read; 1.18 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 174,610\n",
      "Reads with adapters:                    99,596 (57.0%)\n",
      "Reads written (passing filters):        99,596 (57.0%)\n",
      "\n",
      "Total basepairs processed:    65,119,291 bp\n",
      "Total written (filtered):     34,522,850 bp (53.0%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 99596 times; 3' trimmed: 4408 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t110\t0.0\t2\t0 0 110\n",
      "25\t2111\t0.0\t2\t0 2087 24\n",
      "26\t97038\t0.0\t2\t96235 784 19\n",
      "27\t217\t0.0\t2\t0 214 3\n",
      "28\t120\t0.0\t2\t0 0 120\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t4198\t2728.3\t0\t4198\n",
      "4\t125\t682.1\t0\t125\n",
      "5\t3\t170.5\t0\t3\n",
      "6\t21\t42.6\t0\t21\n",
      "7\t36\t10.7\t0\t36\n",
      "10\t1\t0.2\t1\t1\n",
      "11\t5\t0.0\t1\t0 5\n",
      "54\t1\t0.0\t2\t0 1\n",
      "56\t1\t0.0\t2\t1\n",
      "66\t10\t0.0\t2\t9 1\n",
      "67\t5\t0.0\t2\t3 2\n",
      "374\t2\t0.0\t2\t2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleTCGCAT.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleTCGCAT.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 5.52 s (47 us/read; 1.28 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 117,649\n",
      "Reads with adapters:                    69,697 (59.2%)\n",
      "Reads written (passing filters):        69,697 (59.2%)\n",
      "\n",
      "Total basepairs processed:    43,919,703 bp\n",
      "Total written (filtered):     24,174,502 bp (55.0%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 69697 times; 3' trimmed: 3658 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t31\t0.0\t2\t0 0 31\n",
      "25\t406\t0.0\t2\t0 396 10\n",
      "26\t69089\t0.0\t2\t68518 558 13\n",
      "27\t108\t0.0\t2\t0 108\n",
      "28\t63\t0.0\t2\t0 0 63\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3407\t1838.3\t0\t3407\n",
      "4\t154\t459.6\t0\t154\n",
      "5\t6\t114.9\t0\t6\n",
      "6\t18\t28.7\t0\t18\n",
      "7\t33\t7.2\t0\t33\n",
      "11\t5\t0.0\t1\t0 5\n",
      "66\t5\t0.0\t2\t4 1\n",
      "67\t4\t0.0\t2\t4\n",
      "98\t1\t0.0\t2\t1\n",
      "365\t1\t0.0\t2\t0 1\n",
      "368\t1\t0.0\t2\t1\n",
      "369\t1\t0.0\t2\t1\n",
      "373\t2\t0.0\t2\t1 1\n",
      "374\t20\t0.0\t2\t18 1 1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleTCGTCA.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleTCGTCA.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 4.93 s (47 us/read; 1.28 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 105,449\n",
      "Reads with adapters:                    66,197 (62.8%)\n",
      "Reads written (passing filters):        66,197 (62.8%)\n",
      "\n",
      "Total basepairs processed:    39,323,159 bp\n",
      "Total written (filtered):     22,936,114 bp (58.3%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 66197 times; 3' trimmed: 2924 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t19\t0.0\t2\t0 0 19\n",
      "25\t440\t0.0\t2\t0 435 5\n",
      "26\t65616\t0.0\t2\t65112 499 5\n",
      "27\t97\t0.0\t2\t0 97\n",
      "28\t25\t0.0\t2\t0 0 25\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t2805\t1647.6\t0\t2805\n",
      "4\t66\t411.9\t0\t66\n",
      "5\t7\t103.0\t0\t7\n",
      "6\t7\t25.7\t0\t7\n",
      "7\t14\t6.4\t0\t14\n",
      "10\t2\t0.1\t1\t0 2\n",
      "11\t9\t0.0\t1\t0 9\n",
      "66\t8\t0.0\t2\t8\n",
      "67\t4\t0.0\t2\t4\n",
      "374\t2\t0.0\t2\t2\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleTGTATG.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleTGTATG.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 6.99 s (50 us/read; 1.21 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 140,882\n",
      "Reads with adapters:                    83,709 (59.4%)\n",
      "Reads written (passing filters):        83,709 (59.4%)\n",
      "\n",
      "Total basepairs processed:    52,499,024 bp\n",
      "Total written (filtered):     28,972,384 bp (55.2%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 83709 times; 3' trimmed: 8036 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t46\t0.0\t2\t0 0 46\n",
      "25\t582\t0.0\t2\t0 570 12\n",
      "26\t82759\t0.0\t2\t82068 681 10\n",
      "27\t204\t0.0\t2\t0 199 5\n",
      "28\t118\t0.0\t2\t0 0 118\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3935\t2201.3\t0\t3935\n",
      "4\t939\t550.3\t0\t939\n",
      "5\t138\t137.6\t0\t138\n",
      "6\t143\t34.4\t0\t143\n",
      "7\t2849\t8.6\t0\t2849\n",
      "10\t1\t0.1\t1\t0 1\n",
      "11\t15\t0.0\t1\t0 15\n",
      "49\t1\t0.0\t2\t1\n",
      "63\t1\t0.0\t2\t1\n",
      "66\t7\t0.0\t2\t6 0 1\n",
      "67\t6\t0.0\t2\t6\n",
      "374\t1\t0.0\t2\t1\n",
      "\n",
      "This is cutadapt 1.17 with Python 2.7.10\n",
      "Command line parameters: -a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA -o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleunknown.fasta --discard-untrimmed /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sampleunknown.fasta\n",
      "Running on 1 core\n",
      "Trimming 1 adapter with at most 10.0% errors in single-end mode ...\n",
      "Finished in 4.99 s (24 us/read; 2.52 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 209,808\n",
      "Reads with adapters:                    15,667 (7.5%)\n",
      "Reads written (passing filters):        15,667 (7.5%)\n",
      "\n",
      "Total basepairs processed:    79,026,464 bp\n",
      "Total written (filtered):      5,431,172 bp (6.9%)\n",
      "\n",
      "=== Adapter 2 ===\n",
      "\n",
      "Sequence: GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA; Type: linked; Length: 26+26; 5' trimmed: 15667 times; 3' trimmed: 1392 times\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "No. of allowed errors:\n",
      "0-9 bp: 0; 10-19 bp: 1; 20-26 bp: 2\n",
      "\n",
      "Overview of removed sequences at 5' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "24\t940\t0.0\t2\t0 0 940\n",
      "25\t1846\t0.0\t2\t0 1815 31\n",
      "26\t8376\t0.0\t2\t8251 108 17\n",
      "27\t2326\t0.0\t2\t0 2287 39\n",
      "28\t2179\t0.0\t2\t0 0 2179\n",
      "\n",
      "\n",
      "Overview of removed sequences at 3' end\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t772\t3278.2\t0\t772\n",
      "4\t441\t819.6\t0\t441\n",
      "5\t6\t204.9\t0\t6\n",
      "6\t71\t51.2\t0\t71\n",
      "7\t64\t12.8\t0\t64\n",
      "10\t3\t0.2\t1\t0 3\n",
      "11\t25\t0.1\t1\t0 25\n",
      "66\t2\t0.0\t2\t2\n",
      "101\t1\t0.0\t2\t1\n",
      "342\t1\t0.0\t2\t1\n",
      "362\t1\t0.0\t2\t1\n",
      "371\t1\t0.0\t2\t0 1\n",
      "374\t4\t0.0\t2\t3 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!find /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sample*.fasta \\\n",
    "| xargs basename -s .fasta | xargs -I{} \\\n",
    "cutadapt \\\n",
    "-a GGWACWGGWTGAACWGTWTAYCCYCC...TANACYTCNGGRTGNCCRAARAAYCA \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/{}.fasta --discard-untrimmed \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/{}.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACACAC.fasta 100%       \n",
      "20825293 nt in 60096 seqs, min 50, max 454, avg 347\n",
      "Sorting 100%\n",
      "49436 unique sequences, avg cluster 1.2, median 1, max 42\n",
      "Writing output file 100%  \n",
      "4332 uniques written, 45104 clusters discarded (91.2%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACAGCA.fasta 100%        \n",
      "21974071 nt in 63353 seqs, min 61, max 452, avg 347\n",
      "Sorting 100%\n",
      "49161 unique sequences, avg cluster 1.3, median 1, max 84\n",
      "Writing output file 100%  \n",
      "3778 uniques written, 45383 clusters discarded (92.3%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACATGT.fasta 100%       \n",
      "16285414 nt in 46992 seqs, min 50, max 455, avg 347\n",
      "Sorting 100%\n",
      "31840 unique sequences, avg cluster 1.5, median 1, max 90\n",
      "Writing output file 100%  \n",
      "3590 uniques written, 28250 clusters discarded (88.7%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleACGACG.fasta 100%         \n",
      "22589788 nt in 65093 seqs, min 39, max 448, avg 347\n",
      "minseqlength 32: 1 sequence discarded.\n",
      "Sorting 100%\n",
      "51963 unique sequences, avg cluster 1.3, median 1, max 56\n",
      "Writing output file 100%  \n",
      "4127 uniques written, 47836 clusters discarded (92.1%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleATATCG.fasta 100%      \n",
      "19318540 nt in 55745 seqs, min 46, max 455, avg 347\n",
      "Sorting 100%\n",
      "45052 unique sequences, avg cluster 1.2, median 1, max 49\n",
      "Writing output file 100%  \n",
      "3820 uniques written, 41232 clusters discarded (91.5%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleATCAGT.fasta 100%  \n",
      "43531 nt in 125 seqs, min 333, max 413, avg 348\n",
      "Sorting 100%\n",
      "125 unique sequences, avg cluster 1.0, median 1, max 1\n",
      "Writing output file 100% \n",
      "0 uniques written, 125 clusters discarded (100.0%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleCGACGC.fasta 100%           \n",
      "29897382 nt in 86088 seqs, min 285, max 456, avg 347\n",
      "Sorting 100%\n",
      "70654 unique sequences, avg cluster 1.2, median 1, max 42\n",
      "Writing output file 100%  \n",
      "5066 uniques written, 65588 clusters discarded (92.8%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleCTCGCA.fasta 100%          \n",
      "23725887 nt in 68393 seqs, min 37, max 446, avg 347\n",
      "Sorting 100%\n",
      "52549 unique sequences, avg cluster 1.3, median 1, max 66\n",
      "Writing output file 100%  \n",
      "4488 uniques written, 48061 clusters discarded (91.5%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGATGAC.fasta 100%           \n",
      "21820098 nt in 62868 seqs, min 37, max 443, avg 347\n",
      "minseqlength 32: 2 sequences discarded.\n",
      "Sorting 100%\n",
      "39918 unique sequences, avg cluster 1.6, median 1, max 77\n",
      "Writing output file 100%  \n",
      "4365 uniques written, 35553 clusters discarded (89.1%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGCAGTG.fasta 100%         \n",
      "22947576 nt in 66436 seqs, min 282, max 435, avg 345\n",
      "minseqlength 32: 2 sequences discarded.\n",
      "Sorting 100%\n",
      "60253 unique sequences, avg cluster 1.1, median 1, max 25\n",
      "Writing output file 100%  \n",
      "2571 uniques written, 57682 clusters discarded (95.7%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGCGCTC.fasta 100%         \n",
      "21795369 nt in 62728 seqs, min 64, max 454, avg 347\n",
      "Sorting 100%\n",
      "48756 unique sequences, avg cluster 1.3, median 1, max 65\n",
      "Writing output file 100%  \n",
      "3850 uniques written, 44906 clusters discarded (92.1%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleGTCTCT.fasta 100%             \n",
      "34522814 nt in 99594 seqs, min 298, max 448, avg 347\n",
      "minseqlength 32: 2 sequences discarded.\n",
      "Sorting 100%\n",
      "77782 unique sequences, avg cluster 1.3, median 1, max 69\n",
      "Writing output file 100%  \n",
      "6012 uniques written, 71770 clusters discarded (92.3%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleTCGCAT.fasta 100%        \n",
      "24174424 nt in 69693 seqs, min 39, max 455, avg 347\n",
      "minseqlength 32: 4 sequences discarded.\n",
      "Sorting 100%\n",
      "55369 unique sequences, avg cluster 1.3, median 1, max 50\n",
      "Writing output file 100%  \n",
      "4495 uniques written, 50874 clusters discarded (91.9%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleTCGTCA.fasta 100%        \n",
      "22936114 nt in 66197 seqs, min 42, max 457, avg 346\n",
      "Sorting 100%\n",
      "46281 unique sequences, avg cluster 1.4, median 1, max 89\n",
      "Writing output file 100%  \n",
      "4139 uniques written, 42142 clusters discarded (91.1%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleTGTATG.fasta 100%              \n",
      "28972384 nt in 83709 seqs, min 50, max 456, avg 346\n",
      "Sorting 100%\n",
      "66134 unique sequences, avg cluster 1.3, median 1, max 65\n",
      "Writing output file 100%  \n",
      "4655 uniques written, 61479 clusters discarded (93.0%)\n",
      "vsearch v2.8.2_macos_x86_64, 8.0GB RAM, 4 cores\n",
      "https://github.com/torognes/vsearch\n",
      "\n",
      "Dereplicating file /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/sampleunknown.fasta 100%   \n",
      "5431162 nt in 15666 seqs, min 35, max 461, avg 347\n",
      "minseqlength 32: 1 sequence discarded.\n",
      "Sorting 100%\n",
      "15360 unique sequences, avg cluster 1.0, median 1, max 6\n",
      "Writing output file 100%  \n",
      "260 uniques written, 15100 clusters discarded (98.3%)\n"
     ]
    }
   ],
   "source": [
    "!find /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Demultiplexed/sample*.fasta \\\n",
    "| xargs basename -s .fasta | xargs -I{} \\\n",
    "vsearch \\\n",
    "--derep_fulllength /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/NoPrimers/{}.fasta \\\n",
    "--minuniquesize 2 \\\n",
    "--sizeout \\\n",
    "--output /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/{}.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of spaces\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACACAC.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACACAC.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACAGCA.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACAGCA.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACATGT.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACATGT.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleACGACG.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACGACG.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleATATCG.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleATATCG.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleATCAGT.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleATCAGT.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleCGACGC.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleCGACGA.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleCTCGCA.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleCTCGCA.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleGCAGTG.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGATGAC.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleGCAGTG.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGATGAC.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleGCGCTC.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGCGCTC.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleGTCTCT.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGTCTCT.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleTCGCAT.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleTCGCAT.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleTCGTCA.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleTCGTCA.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleTGTATG.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleTGTATG.fasta\n",
    "\n",
    "!sed 's/ //g' /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/sampleunknown.fasta > \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleunkown.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampleATCAGT no unique sequences??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\r\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\r\n",
      "https://github.com/torognes/swarm\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\r\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\r\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\r\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\r\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\r\n",
      "\r\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\r\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACACAC.fasta\r\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACACAC.txt\r\n",
      "Resolution (d):    1\r\n",
      "Threads:           1\r\n",
      "Break OTUs:        Yes\r\n",
      "Fastidious:        No\r\n",
      "\r\n",
      "Reading database:  0%  \r",
      "Reading database:  0%  \r",
      "Reading database:  1%  \r",
      "Reading database:  1%  \r",
      "Reading database:  2%  \r",
      "Reading database:  2%  \r",
      "Reading database:  3%  \r",
      "Reading database:  3%  \r",
      "Reading database:  4%  \r",
      "Reading database:  4%  \r",
      "Reading database:  5%  \r",
      "Reading database:  5%  \r",
      "Reading database:  6%  \r",
      "Reading database:  6%  \r",
      "Reading database:  7%  \r",
      "Reading database:  7%  \r",
      "Reading database:  8%  \r",
      "Reading database:  8%  \r",
      "Reading database:  9%  \r",
      "Reading database:  9%  \r",
      "Reading database:  10%  \r",
      "Reading database:  10%  \r",
      "Reading database:  11%  \r",
      "Reading database:  11%  \r",
      "Reading database:  12%  \r",
      "Reading database:  12%  \r",
      "Reading database:  13%  \r",
      "Reading database:  13%  \r",
      "Reading database:  14%  \r",
      "Reading database:  14%  \r",
      "Reading database:  15%  \r",
      "Reading database:  15%  \r",
      "Reading database:  16%  \r",
      "Reading database:  16%  \r",
      "Reading database:  17%  \r",
      "Reading database:  17%  \r",
      "Reading database:  18%  \r",
      "Reading database:  18%  \r",
      "Reading database:  19%  \r",
      "Reading database:  19%  \r",
      "Reading database:  20%  \r",
      "Reading database:  20%  \r",
      "Reading database:  21%  \r",
      "Reading database:  21%  \r",
      "Reading database:  22%  \r",
      "Reading database:  22%  \r",
      "Reading database:  23%  \r",
      "Reading database:  23%  \r",
      "Reading database:  24%  \r",
      "Reading database:  24%  \r",
      "Reading database:  25%  \r",
      "Reading database:  25%  \r",
      "Reading database:  26%  \r",
      "Reading database:  26%  \r",
      "Reading database:  27%  \r",
      "Reading database:  27%  \r",
      "Reading database:  28%  \r",
      "Reading database:  28%  \r",
      "Reading database:  29%  \r",
      "Reading database:  29%  \r",
      "Reading database:  30%  \r",
      "Reading database:  31%  \r",
      "Reading database:  31%  \r",
      "Reading database:  32%  \r",
      "Reading database:  32%  \r",
      "Reading database:  33%  \r",
      "Reading database:  33%  \r",
      "Reading database:  34%  \r",
      "Reading database:  34%  \r",
      "Reading database:  35%  \r",
      "Reading database:  35%  \r",
      "Reading database:  36%  \r",
      "Reading database:  36%  \r",
      "Reading database:  37%  \r",
      "Reading database:  37%  \r",
      "Reading database:  38%  \r",
      "Reading database:  38%  \r",
      "Reading database:  39%  \r",
      "Reading database:  39%  \r",
      "Reading database:  40%  \r",
      "Reading database:  40%  \r",
      "Reading database:  41%  \r",
      "Reading database:  41%  \r",
      "Reading database:  42%  \r",
      "Reading database:  42%  \r",
      "Reading database:  43%  \r",
      "Reading database:  43%  \r",
      "Reading database:  44%  \r",
      "Reading database:  44%  \r",
      "Reading database:  45%  \r",
      "Reading database:  45%  \r",
      "Reading database:  46%  \r",
      "Reading database:  46%  \r",
      "Reading database:  47%  \r",
      "Reading database:  47%  \r",
      "Reading database:  48%  \r",
      "Reading database:  48%  \r",
      "Reading database:  49%  \r",
      "Reading database:  49%  \r",
      "Reading database:  50%  \r",
      "Reading database:  50%  \r",
      "Reading database:  51%  \r",
      "Reading database:  51%  \r",
      "Reading database:  52%  \r",
      "Reading database:  52%  \r",
      "Reading database:  53%  \r",
      "Reading database:  53%  \r",
      "Reading database:  54%  \r",
      "Reading database:  54%  \r",
      "Reading database:  55%  \r",
      "Reading database:  55%  \r",
      "Reading database:  56%  \r",
      "Reading database:  56%  \r",
      "Reading database:  57%  \r",
      "Reading database:  57%  \r",
      "Reading database:  58%  \r",
      "Reading database:  58%  \r",
      "Reading database:  59%  \r",
      "Reading database:  59%  \r",
      "Reading database:  60%  \r",
      "Reading database:  60%  \r",
      "Reading database:  61%  \r",
      "Reading database:  61%  \r",
      "Reading database:  62%  \r",
      "Reading database:  63%  \r",
      "Reading database:  63%  \r",
      "Reading database:  64%  \r",
      "Reading database:  64%  \r",
      "Reading database:  65%  \r",
      "Reading database:  65%  \r",
      "Reading database:  66%  \r",
      "Reading database:  66%  \r",
      "Reading database:  67%  \r",
      "Reading database:  67%  \r",
      "Reading database:  68%  \r",
      "Reading database:  68%  \r",
      "Reading database:  69%  \r",
      "Reading database:  69%  \r",
      "Reading database:  70%  \r",
      "Reading database:  70%  \r",
      "Reading database:  71%  \r",
      "Reading database:  71%  \r",
      "Reading database:  72%  \r",
      "Reading database:  72%  \r",
      "Reading database:  73%  \r",
      "Reading database:  73%  \r",
      "Reading database:  74%  \r",
      "Reading database:  74%  \r",
      "Reading database:  75%  \r",
      "Reading database:  75%  \r",
      "Reading database:  76%  \r",
      "Reading database:  76%  \r",
      "Reading database:  77%  \r",
      "Reading database:  77%  \r",
      "Reading database:  78%  \r",
      "Reading database:  78%  \r",
      "Reading database:  79%  \r",
      "Reading database:  79%  \r",
      "Reading database:  80%  \r",
      "Reading database:  80%  \r",
      "Reading database:  81%  \r",
      "Reading database:  81%  \r",
      "Reading database:  82%  \r",
      "Reading database:  82%  \r",
      "Reading database:  83%  \r",
      "Reading database:  83%  \r",
      "Reading database:  84%  \r",
      "Reading database:  84%  \r",
      "Reading database:  85%  \r",
      "Reading database:  85%  \r",
      "Reading database:  86%  \r",
      "Reading database:  86%  \r",
      "Reading database:  87%  \r",
      "Reading database:  87%  \r",
      "Reading database:  88%  \r",
      "Reading database:  88%  \r",
      "Reading database:  89%  \r",
      "Reading database:  89%  \r",
      "Reading database:  90%  \r",
      "Reading database:  90%  \r",
      "Reading database:  91%  \r",
      "Reading database:  91%  \r",
      "Reading database:  92%  \r",
      "Reading database:  92%  \r",
      "Reading database:  93%  \r",
      "Reading database:  93%  \r",
      "Reading database:  94%  \r",
      "Reading database:  94%  \r",
      "Reading database:  95%  \r",
      "Reading database:  96%  \r",
      "Reading database:  96%  \r",
      "Reading database:  97%  \r",
      "Reading database:  97%  \r",
      "Reading database:  98%  \r",
      "Reading database:  98%  \r",
      "Reading database:  99%  \r",
      "Reading database:  99%  \r",
      "Reading database:  100%  \r",
      "Reading database:  100%\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing database: 0%  \r",
      "Indexing database: 0%  \r",
      "Indexing database: 0%  \r",
      "Indexing database: 1%  \r",
      "Indexing database: 1%  \r",
      "Indexing database: 2%  \r",
      "Indexing database: 2%  \r",
      "Indexing database: 3%  \r",
      "Indexing database: 3%  \r",
      "Indexing database: 4%  \r",
      "Indexing database: 4%  \r",
      "Indexing database: 5%  \r",
      "Indexing database: 5%  \r",
      "Indexing database: 6%  \r",
      "Indexing database: 6%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 8%  \r",
      "Indexing database: 8%  \r",
      "Indexing database: 9%  \r",
      "Indexing database: 9%  \r",
      "Indexing database: 10%  \r",
      "Indexing database: 10%  \r",
      "Indexing database: 11%  \r",
      "Indexing database: 11%  \r",
      "Indexing database: 12%  \r",
      "Indexing database: 12%  \r",
      "Indexing database: 13%  \r",
      "Indexing database: 13%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 15%  \r",
      "Indexing database: 15%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 17%  \r",
      "Indexing database: 17%  \r",
      "Indexing database: 18%  \r",
      "Indexing database: 18%  \r",
      "Indexing database: 19%  \r",
      "Indexing database: 19%  \r",
      "Indexing database: 20%  \r",
      "Indexing database: 20%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 22%  \r",
      "Indexing database: 22%  \r",
      "Indexing database: 23%  \r",
      "Indexing database: 23%  \r",
      "Indexing database: 24%  \r",
      "Indexing database: 24%  \r",
      "Indexing database: 25%  \r",
      "Indexing database: 25%  \r",
      "Indexing database: 26%  \r",
      "Indexing database: 26%  \r",
      "Indexing database: 27%  \r",
      "Indexing database: 27%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 29%  \r",
      "Indexing database: 29%  \r",
      "Indexing database: 30%  \r",
      "Indexing database: 30%  \r",
      "Indexing database: 31%  \r",
      "Indexing database: 31%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 33%  \r",
      "Indexing database: 33%  \r",
      "Indexing database: 34%  \r",
      "Indexing database: 34%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 36%  \r",
      "Indexing database: 36%  \r",
      "Indexing database: 37%  \r",
      "Indexing database: 37%  \r",
      "Indexing database: 38%  \r",
      "Indexing database: 38%  \r",
      "Indexing database: 39%  \r",
      "Indexing database: 39%  \r",
      "Indexing database: 40%  \r",
      "Indexing database: 40%  \r",
      "Indexing database: 41%  \r",
      "Indexing database: 41%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 43%  \r",
      "Indexing database: 43%  \r",
      "Indexing database: 44%  \r",
      "Indexing database: 44%  \r",
      "Indexing database: 45%  \r",
      "Indexing database: 45%  \r",
      "Indexing database: 46%  \r",
      "Indexing database: 46%  \r",
      "Indexing database: 47%  \r",
      "Indexing database: 47%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 50%  \r",
      "Indexing database: 50%  \r",
      "Indexing database: 51%  \r",
      "Indexing database: 51%  \r",
      "Indexing database: 52%  \r",
      "Indexing database: 52%  \r",
      "Indexing database: 53%  \r",
      "Indexing database: 53%  \r",
      "Indexing database: 54%  \r",
      "Indexing database: 54%  \r",
      "Indexing database: 55%  \r",
      "Indexing database: 55%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 57%  \r",
      "Indexing database: 57%  \r",
      "Indexing database: 58%  \r",
      "Indexing database: 58%  \r",
      "Indexing database: 59%  \r",
      "Indexing database: 59%  \r",
      "Indexing database: 60%  \r",
      "Indexing database: 60%  \r",
      "Indexing database: 61%  \r",
      "Indexing database: 61%  \r",
      "Indexing database: 62%  \r",
      "Indexing database: 62%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 65%  \r",
      "Indexing database: 65%  \r",
      "Indexing database: 66%  \r",
      "Indexing database: 66%  \r",
      "Indexing database: 67%  \r",
      "Indexing database: 67%  \r",
      "Indexing database: 68%  \r",
      "Indexing database: 68%  \r",
      "Indexing database: 69%  \r",
      "Indexing database: 69%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 71%  \r",
      "Indexing database: 71%  \r",
      "Indexing database: 72%  \r",
      "Indexing database: 72%  \r",
      "Indexing database: 73%  \r",
      "Indexing database: 73%  \r",
      "Indexing database: 74%  \r",
      "Indexing database: 74%  \r",
      "Indexing database: 75%  \r",
      "Indexing database: 75%  \r",
      "Indexing database: 76%  \r",
      "Indexing database: 76%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 78%  \r",
      "Indexing database: 78%  \r",
      "Indexing database: 79%  \r",
      "Indexing database: 79%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 81%  \r",
      "Indexing database: 81%  \r",
      "Indexing database: 82%  \r",
      "Indexing database: 82%  \r",
      "Indexing database: 83%  \r",
      "Indexing database: 83%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 85%  \r",
      "Indexing database: 85%  \r",
      "Indexing database: 86%  \r",
      "Indexing database: 86%  \r",
      "Indexing database: 87%  \r",
      "Indexing database: 87%  \r",
      "Indexing database: 88%  \r",
      "Indexing database: 88%  \r",
      "Indexing database: 89%  \r",
      "Indexing database: 89%  \r",
      "Indexing database: 90%  \r",
      "Indexing database: 90%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 92%  \r",
      "Indexing database: 92%  \r",
      "Indexing database: 93%  \r",
      "Indexing database: 93%  \r",
      "Indexing database: 94%  \r",
      "Indexing database: 94%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 96%  \r",
      "Indexing database: 96%  \r",
      "Indexing database: 97%  \r",
      "Indexing database: 97%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 99%  \r",
      "Indexing database: 99%  \r",
      "Indexing database: 100%  \r",
      "Indexing database: 100%\r\n",
      "Database info:     1501897 nt in 4332 sequences, longest 351 nt\r\n",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 1%  \r",
      "Hashing sequences: 1%  \r",
      "Hashing sequences: 2%  \r",
      "Hashing sequences: 2%  \r",
      "Hashing sequences: 3%  \r",
      "Hashing sequences: 3%  \r",
      "Hashing sequences: 4%  \r",
      "Hashing sequences: 4%  \r",
      "Hashing sequences: 5%  \r",
      "Hashing sequences: 5%  \r",
      "Hashing sequences: 6%  \r",
      "Hashing sequences: 6%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 8%  \r",
      "Hashing sequences: 8%  \r",
      "Hashing sequences: 9%  \r",
      "Hashing sequences: 9%  \r",
      "Hashing sequences: 10%  \r",
      "Hashing sequences: 10%  \r",
      "Hashing sequences: 11%  \r",
      "Hashing sequences: 11%  \r",
      "Hashing sequences: 12%  \r",
      "Hashing sequences: 12%  \r",
      "Hashing sequences: 13%  \r",
      "Hashing sequences: 13%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 15%  \r",
      "Hashing sequences: 15%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 17%  \r",
      "Hashing sequences: 17%  \r",
      "Hashing sequences: 18%  \r",
      "Hashing sequences: 18%  \r",
      "Hashing sequences: 19%  \r",
      "Hashing sequences: 19%  \r",
      "Hashing sequences: 20%  \r",
      "Hashing sequences: 20%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 22%  \r",
      "Hashing sequences: 22%  \r",
      "Hashing sequences: 23%  \r",
      "Hashing sequences: 23%  \r",
      "Hashing sequences: 24%  \r",
      "Hashing sequences: 24%  \r",
      "Hashing sequences: 25%  \r",
      "Hashing sequences: 25%  \r",
      "Hashing sequences: 26%  \r",
      "Hashing sequences: 26%  \r",
      "Hashing sequences: 27%  \r",
      "Hashing sequences: 27%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 29%  \r",
      "Hashing sequences: 29%  \r",
      "Hashing sequences: 30%  \r",
      "Hashing sequences: 30%  \r",
      "Hashing sequences: 31%  \r",
      "Hashing sequences: 31%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 33%  \r",
      "Hashing sequences: 33%  \r",
      "Hashing sequences: 34%  \r",
      "Hashing sequences: 34%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 36%  \r",
      "Hashing sequences: 36%  \r",
      "Hashing sequences: 37%  \r",
      "Hashing sequences: 37%  \r",
      "Hashing sequences: 38%  \r",
      "Hashing sequences: 38%  \r",
      "Hashing sequences: 39%  \r",
      "Hashing sequences: 39%  \r",
      "Hashing sequences: 40%  \r",
      "Hashing sequences: 40%  \r",
      "Hashing sequences: 41%  \r",
      "Hashing sequences: 41%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 43%  \r",
      "Hashing sequences: 43%  \r",
      "Hashing sequences: 44%  \r",
      "Hashing sequences: 44%  \r",
      "Hashing sequences: 45%  \r",
      "Hashing sequences: 45%  \r",
      "Hashing sequences: 46%  \r",
      "Hashing sequences: 46%  \r",
      "Hashing sequences: 47%  \r",
      "Hashing sequences: 47%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 50%  \r",
      "Hashing sequences: 50%  \r",
      "Hashing sequences: 51%  \r",
      "Hashing sequences: 51%  \r",
      "Hashing sequences: 52%  \r",
      "Hashing sequences: 52%  \r",
      "Hashing sequences: 53%  \r",
      "Hashing sequences: 53%  \r",
      "Hashing sequences: 54%  \r",
      "Hashing sequences: 54%  \r",
      "Hashing sequences: 55%  \r",
      "Hashing sequences: 55%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 57%  \r",
      "Hashing sequences: 57%  \r",
      "Hashing sequences: 58%  \r",
      "Hashing sequences: 58%  \r",
      "Hashing sequences: 59%  \r",
      "Hashing sequences: 59%  \r",
      "Hashing sequences: 60%  \r",
      "Hashing sequences: 60%  \r",
      "Hashing sequences: 61%  \r",
      "Hashing sequences: 61%  \r",
      "Hashing sequences: 62%  \r",
      "Hashing sequences: 62%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 65%  \r",
      "Hashing sequences: 65%  \r",
      "Hashing sequences: 66%  \r",
      "Hashing sequences: 66%  \r",
      "Hashing sequences: 67%  \r",
      "Hashing sequences: 67%  \r",
      "Hashing sequences: 68%  \r",
      "Hashing sequences: 68%  \r",
      "Hashing sequences: 69%  \r",
      "Hashing sequences: 69%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 71%  \r",
      "Hashing sequences: 71%  \r",
      "Hashing sequences: 72%  \r",
      "Hashing sequences: 72%  \r",
      "Hashing sequences: 73%  \r",
      "Hashing sequences: 73%  \r",
      "Hashing sequences: 74%  \r",
      "Hashing sequences: 74%  \r",
      "Hashing sequences: 75%  \r",
      "Hashing sequences: 75%  \r",
      "Hashing sequences: 76%  \r",
      "Hashing sequences: 76%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 78%  \r",
      "Hashing sequences: 78%  \r",
      "Hashing sequences: 79%  \r",
      "Hashing sequences: 79%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 81%  \r",
      "Hashing sequences: 81%  \r",
      "Hashing sequences: 82%  \r",
      "Hashing sequences: 82%  \r",
      "Hashing sequences: 83%  \r",
      "Hashing sequences: 83%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 85%  \r",
      "Hashing sequences: 85%  \r",
      "Hashing sequences: 86%  \r",
      "Hashing sequences: 86%  \r",
      "Hashing sequences: 87%  \r",
      "Hashing sequences: 87%  \r",
      "Hashing sequences: 88%  \r",
      "Hashing sequences: 88%  \r",
      "Hashing sequences: 89%  \r",
      "Hashing sequences: 89%  \r",
      "Hashing sequences: 90%  \r",
      "Hashing sequences: 90%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 92%  \r",
      "Hashing sequences: 92%  \r",
      "Hashing sequences: 93%  \r",
      "Hashing sequences: 93%  \r",
      "Hashing sequences: 94%  \r",
      "Hashing sequences: 94%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 96%  \r",
      "Hashing sequences: 96%  \r",
      "Hashing sequences: 97%  \r",
      "Hashing sequences: 97%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 99%  \r",
      "Hashing sequences: 99%  \r",
      "Hashing sequences: 100%  \r",
      "Hashing sequences: 100%\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering:        100%              \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  583\n",
      "Largest swarm:     1073\n",
      "Max generations:   21\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACAGCA.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACAGCA.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1310860 nt in 3778 sequences, longest 349 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%          \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  292\n",
      "Largest swarm:     1476\n",
      "Max generations:   9\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACATGT.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACATGT.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%  \n",
      "Database info:     1244083 nt in 3590 sequences, longest 349 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%          \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  233\n",
      "Largest swarm:     1886\n",
      "Max generations:   22\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleACGACG.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACGACG.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%  \n",
      "Database info:     1432669 nt in 4127 sequences, longest 351 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%              \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  490\n",
      "Largest swarm:     1394\n",
      "Max generations:   9\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleATATCG.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleATATCG.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1324809 nt in 3820 sequences, longest 348 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%                \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  470\n",
      "Largest swarm:     958\n",
      "Max generations:   9\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleATCAGT.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleATCAGT.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%\n",
      "Indexing database: 100%\n",
      "Database info:     0 nt in 0 sequences, longest 0 nt\n",
      "Hashing sequences: 100%\n",
      "Clustering:        100%\n",
      "Writing swarms:    100%\n",
      "Writing seeds:     100%\n",
      "\n",
      "Number of swarms:  0\n",
      "Largest swarm:     0\n",
      "Max generations:   0\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleCGACGA.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleCGACGA.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1759847 nt in 5066 sequences, longest 351 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%              \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  557\n",
      "Largest swarm:     1415\n",
      "Max generations:   9\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleCTCGCA.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleCTCGCA.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1558045 nt in 4488 sequences, longest 349 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%          \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  364\n",
      "Largest swarm:     1553\n",
      "Max generations:   14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\r\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\r\n",
      "https://github.com/torognes/swarm\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\r\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\r\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\r\n",
      "\r\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\r\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\r\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\r\n",
      "\r\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\r\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGATGAC.fasta\r\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleGATGAC.txt\r\n",
      "Resolution (d):    1\r\n",
      "Threads:           1\r\n",
      "Break OTUs:        Yes\r\n",
      "Fastidious:        No\r\n",
      "\r\n",
      "Reading database:  0%  \r",
      "Reading database:  0%  \r",
      "Reading database:  1%  \r",
      "Reading database:  1%  \r",
      "Reading database:  2%  \r",
      "Reading database:  2%  \r",
      "Reading database:  3%  \r",
      "Reading database:  3%  \r",
      "Reading database:  4%  \r",
      "Reading database:  4%  \r",
      "Reading database:  5%  \r",
      "Reading database:  5%  \r",
      "Reading database:  6%  \r",
      "Reading database:  6%  \r",
      "Reading database:  7%  \r",
      "Reading database:  7%  \r",
      "Reading database:  8%  \r",
      "Reading database:  8%  \r",
      "Reading database:  9%  \r",
      "Reading database:  9%  \r",
      "Reading database:  10%  \r",
      "Reading database:  10%  \r",
      "Reading database:  11%  \r",
      "Reading database:  11%  \r",
      "Reading database:  12%  \r",
      "Reading database:  12%  \r",
      "Reading database:  13%  \r",
      "Reading database:  13%  \r",
      "Reading database:  14%  \r",
      "Reading database:  14%  \r",
      "Reading database:  15%  \r",
      "Reading database:  15%  \r",
      "Reading database:  16%  \r",
      "Reading database:  16%  \r",
      "Reading database:  17%  \r",
      "Reading database:  17%  \r",
      "Reading database:  18%  \r",
      "Reading database:  18%  \r",
      "Reading database:  19%  \r",
      "Reading database:  19%  \r",
      "Reading database:  20%  \r",
      "Reading database:  20%  \r",
      "Reading database:  21%  \r",
      "Reading database:  21%  \r",
      "Reading database:  22%  \r",
      "Reading database:  22%  \r",
      "Reading database:  23%  \r",
      "Reading database:  23%  \r",
      "Reading database:  24%  \r",
      "Reading database:  24%  \r",
      "Reading database:  25%  \r",
      "Reading database:  25%  \r",
      "Reading database:  26%  \r",
      "Reading database:  26%  \r",
      "Reading database:  27%  \r",
      "Reading database:  27%  \r",
      "Reading database:  28%  \r",
      "Reading database:  28%  \r",
      "Reading database:  29%  \r",
      "Reading database:  29%  \r",
      "Reading database:  30%  \r",
      "Reading database:  30%  \r",
      "Reading database:  31%  \r",
      "Reading database:  31%  \r",
      "Reading database:  32%  \r",
      "Reading database:  33%  \r",
      "Reading database:  33%  \r",
      "Reading database:  34%  \r",
      "Reading database:  34%  \r",
      "Reading database:  35%  \r",
      "Reading database:  35%  \r",
      "Reading database:  36%  \r",
      "Reading database:  36%  \r",
      "Reading database:  37%  \r",
      "Reading database:  37%  \r",
      "Reading database:  38%  \r",
      "Reading database:  38%  \r",
      "Reading database:  39%  \r",
      "Reading database:  39%  \r",
      "Reading database:  40%  \r",
      "Reading database:  40%  \r",
      "Reading database:  41%  \r",
      "Reading database:  41%  \r",
      "Reading database:  42%  \r",
      "Reading database:  42%  \r",
      "Reading database:  43%  \r",
      "Reading database:  43%  \r",
      "Reading database:  44%  \r",
      "Reading database:  44%  \r",
      "Reading database:  45%  \r",
      "Reading database:  45%  \r",
      "Reading database:  46%  \r",
      "Reading database:  46%  \r",
      "Reading database:  47%  \r",
      "Reading database:  47%  \r",
      "Reading database:  48%  \r",
      "Reading database:  48%  \r",
      "Reading database:  49%  \r",
      "Reading database:  49%  \r",
      "Reading database:  50%  \r",
      "Reading database:  50%  \r",
      "Reading database:  51%  \r",
      "Reading database:  51%  \r",
      "Reading database:  52%  \r",
      "Reading database:  52%  \r",
      "Reading database:  53%  \r",
      "Reading database:  53%  \r",
      "Reading database:  54%  \r",
      "Reading database:  54%  \r",
      "Reading database:  55%  \r",
      "Reading database:  55%  \r",
      "Reading database:  56%  \r",
      "Reading database:  56%  \r",
      "Reading database:  57%  \r",
      "Reading database:  57%  \r",
      "Reading database:  58%  \r",
      "Reading database:  58%  \r",
      "Reading database:  59%  \r",
      "Reading database:  59%  \r",
      "Reading database:  60%  \r",
      "Reading database:  60%  \r",
      "Reading database:  61%  \r",
      "Reading database:  61%  \r",
      "Reading database:  62%  \r",
      "Reading database:  62%  \r",
      "Reading database:  63%  \r",
      "Reading database:  63%  \r",
      "Reading database:  64%  \r",
      "Reading database:  64%  \r",
      "Reading database:  65%  \r",
      "Reading database:  65%  \r",
      "Reading database:  66%  \r",
      "Reading database:  66%  \r",
      "Reading database:  67%  \r",
      "Reading database:  67%  \r",
      "Reading database:  68%  \r",
      "Reading database:  68%  \r",
      "Reading database:  69%  \r",
      "Reading database:  69%  \r",
      "Reading database:  70%  \r",
      "Reading database:  70%  \r",
      "Reading database:  71%  \r",
      "Reading database:  71%  \r",
      "Reading database:  72%  \r",
      "Reading database:  72%  \r",
      "Reading database:  73%  \r",
      "Reading database:  73%  \r",
      "Reading database:  74%  \r",
      "Reading database:  74%  \r",
      "Reading database:  75%  \r",
      "Reading database:  76%  \r",
      "Reading database:  76%  \r",
      "Reading database:  77%  \r",
      "Reading database:  77%  \r",
      "Reading database:  78%  \r",
      "Reading database:  78%  \r",
      "Reading database:  79%  \r",
      "Reading database:  79%  \r",
      "Reading database:  80%  \r",
      "Reading database:  80%  \r",
      "Reading database:  81%  \r",
      "Reading database:  81%  \r",
      "Reading database:  82%  \r",
      "Reading database:  82%  \r",
      "Reading database:  83%  \r",
      "Reading database:  83%  \r",
      "Reading database:  84%  \r",
      "Reading database:  84%  \r",
      "Reading database:  85%  \r",
      "Reading database:  85%  \r",
      "Reading database:  86%  \r",
      "Reading database:  86%  \r",
      "Reading database:  87%  \r",
      "Reading database:  87%  \r",
      "Reading database:  88%  \r",
      "Reading database:  88%  \r",
      "Reading database:  89%  \r",
      "Reading database:  89%  \r",
      "Reading database:  90%  \r",
      "Reading database:  90%  \r",
      "Reading database:  91%  \r",
      "Reading database:  91%  \r",
      "Reading database:  92%  \r",
      "Reading database:  92%  \r",
      "Reading database:  93%  \r",
      "Reading database:  93%  \r",
      "Reading database:  94%  \r",
      "Reading database:  94%  \r",
      "Reading database:  95%  \r",
      "Reading database:  95%  \r",
      "Reading database:  96%  \r",
      "Reading database:  96%  \r",
      "Reading database:  97%  \r",
      "Reading database:  97%  \r",
      "Reading database:  98%  \r",
      "Reading database:  98%  \r",
      "Reading database:  99%  \r",
      "Reading database:  99%  \r",
      "Reading database:  100%  \r",
      "Reading database:  100%\r\n",
      "Indexing database: 0%  \r",
      "Indexing database: 0%  \r",
      "Indexing database: 0%  \r",
      "Indexing database: 1%  \r",
      "Indexing database: 1%  \r",
      "Indexing database: 2%  \r",
      "Indexing database: 2%  \r",
      "Indexing database: 3%  \r",
      "Indexing database: 3%  \r",
      "Indexing database: 4%  \r",
      "Indexing database: 4%  \r",
      "Indexing database: 5%  \r",
      "Indexing database: 5%  \r",
      "Indexing database: 6%  \r",
      "Indexing database: 6%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 7%  \r",
      "Indexing database: 8%  \r",
      "Indexing database: 8%  \r",
      "Indexing database: 9%  \r",
      "Indexing database: 9%  \r",
      "Indexing database: 10%  \r",
      "Indexing database: 10%  \r",
      "Indexing database: 11%  \r",
      "Indexing database: 11%  \r",
      "Indexing database: 12%  \r",
      "Indexing database: 12%  \r",
      "Indexing database: 13%  \r",
      "Indexing database: 13%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 14%  \r",
      "Indexing database: 15%  \r",
      "Indexing database: 15%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 16%  \r",
      "Indexing database: 17%  \r",
      "Indexing database: 17%  \r",
      "Indexing database: 18%  \r",
      "Indexing database: 18%  \r",
      "Indexing database: 19%  \r",
      "Indexing database: 19%  \r",
      "Indexing database: 20%  \r",
      "Indexing database: 20%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 21%  \r",
      "Indexing database: 22%  \r",
      "Indexing database: 22%  \r",
      "Indexing database: 23%  \r",
      "Indexing database: 23%  \r",
      "Indexing database: 24%  \r",
      "Indexing database: 24%  \r",
      "Indexing database: 25%  \r",
      "Indexing database: 25%  \r",
      "Indexing database: 26%  \r",
      "Indexing database: 26%  \r",
      "Indexing database: 27%  \r",
      "Indexing database: 27%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 28%  \r",
      "Indexing database: 29%  \r",
      "Indexing database: 29%  \r",
      "Indexing database: 30%  \r",
      "Indexing database: 30%  \r",
      "Indexing database: 31%  \r",
      "Indexing database: 31%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 32%  \r",
      "Indexing database: 33%  \r",
      "Indexing database: 33%  \r",
      "Indexing database: 34%  \r",
      "Indexing database: 34%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 35%  \r",
      "Indexing database: 36%  \r",
      "Indexing database: 36%  \r",
      "Indexing database: 37%  \r",
      "Indexing database: 37%  \r",
      "Indexing database: 38%  \r",
      "Indexing database: 38%  \r",
      "Indexing database: 39%  \r",
      "Indexing database: 39%  \r",
      "Indexing database: 40%  \r",
      "Indexing database: 40%  \r",
      "Indexing database: 41%  \r",
      "Indexing database: 41%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 42%  \r",
      "Indexing database: 43%  \r",
      "Indexing database: 43%  \r",
      "Indexing database: 44%  \r",
      "Indexing database: 44%  \r",
      "Indexing database: 45%  \r",
      "Indexing database: 45%  \r",
      "Indexing database: 46%  \r",
      "Indexing database: 46%  \r",
      "Indexing database: 47%  \r",
      "Indexing database: 47%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 48%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 49%  \r",
      "Indexing database: 50%  \r",
      "Indexing database: 50%  \r",
      "Indexing database: 51%  \r",
      "Indexing database: 51%  \r",
      "Indexing database: 52%  \r",
      "Indexing database: 52%  \r",
      "Indexing database: 53%  \r",
      "Indexing database: 53%  \r",
      "Indexing database: 54%  \r",
      "Indexing database: 54%  \r",
      "Indexing database: 55%  \r",
      "Indexing database: 55%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 56%  \r",
      "Indexing database: 57%  \r",
      "Indexing database: 57%  \r",
      "Indexing database: 58%  \r",
      "Indexing database: 58%  \r",
      "Indexing database: 59%  \r",
      "Indexing database: 59%  \r",
      "Indexing database: 60%  \r",
      "Indexing database: 60%  \r",
      "Indexing database: 61%  \r",
      "Indexing database: 61%  \r",
      "Indexing database: 62%  \r",
      "Indexing database: 62%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 63%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 64%  \r",
      "Indexing database: 65%  \r",
      "Indexing database: 65%  \r",
      "Indexing database: 66%  \r",
      "Indexing database: 66%  \r",
      "Indexing database: 67%  \r",
      "Indexing database: 67%  \r",
      "Indexing database: 68%  \r",
      "Indexing database: 68%  \r",
      "Indexing database: 69%  \r",
      "Indexing database: 69%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 70%  \r",
      "Indexing database: 71%  \r",
      "Indexing database: 71%  \r",
      "Indexing database: 72%  \r",
      "Indexing database: 72%  \r",
      "Indexing database: 73%  \r",
      "Indexing database: 73%  \r",
      "Indexing database: 74%  \r",
      "Indexing database: 74%  \r",
      "Indexing database: 75%  \r",
      "Indexing database: 75%  \r",
      "Indexing database: 76%  \r",
      "Indexing database: 76%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 77%  \r",
      "Indexing database: 78%  \r",
      "Indexing database: 78%  \r",
      "Indexing database: 79%  \r",
      "Indexing database: 79%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 80%  \r",
      "Indexing database: 81%  \r",
      "Indexing database: 81%  \r",
      "Indexing database: 82%  \r",
      "Indexing database: 82%  \r",
      "Indexing database: 83%  \r",
      "Indexing database: 83%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 84%  \r",
      "Indexing database: 85%  \r",
      "Indexing database: 85%  \r",
      "Indexing database: 86%  \r",
      "Indexing database: 86%  \r",
      "Indexing database: 87%  \r",
      "Indexing database: 87%  \r",
      "Indexing database: 88%  \r",
      "Indexing database: 88%  \r",
      "Indexing database: 89%  \r",
      "Indexing database: 89%  \r",
      "Indexing database: 90%  \r",
      "Indexing database: 90%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 91%  \r",
      "Indexing database: 92%  \r",
      "Indexing database: 92%  \r",
      "Indexing database: 93%  \r",
      "Indexing database: 93%  \r",
      "Indexing database: 94%  \r",
      "Indexing database: 94%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 95%  \r",
      "Indexing database: 96%  \r",
      "Indexing database: 96%  \r",
      "Indexing database: 97%  \r",
      "Indexing database: 97%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 98%  \r",
      "Indexing database: 99%  \r",
      "Indexing database: 99%  \r",
      "Indexing database: 100%  \r",
      "Indexing database: 100%\r\n",
      "Database info:     887413 nt in 2571 sequences, longest 349 nt\r\n",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 0%  \r",
      "Hashing sequences: 1%  \r",
      "Hashing sequences: 1%  \r",
      "Hashing sequences: 2%  \r",
      "Hashing sequences: 2%  \r",
      "Hashing sequences: 3%  \r",
      "Hashing sequences: 3%  \r",
      "Hashing sequences: 4%  \r",
      "Hashing sequences: 4%  \r",
      "Hashing sequences: 5%  \r",
      "Hashing sequences: 5%  \r",
      "Hashing sequences: 6%  \r",
      "Hashing sequences: 6%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 7%  \r",
      "Hashing sequences: 8%  \r",
      "Hashing sequences: 8%  \r",
      "Hashing sequences: 9%  \r",
      "Hashing sequences: 9%  \r",
      "Hashing sequences: 10%  \r",
      "Hashing sequences: 10%  \r",
      "Hashing sequences: 11%  \r",
      "Hashing sequences: 11%  \r",
      "Hashing sequences: 12%  \r",
      "Hashing sequences: 12%  \r",
      "Hashing sequences: 13%  \r",
      "Hashing sequences: 13%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 14%  \r",
      "Hashing sequences: 15%  \r",
      "Hashing sequences: 15%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 16%  \r",
      "Hashing sequences: 17%  \r",
      "Hashing sequences: 17%  \r",
      "Hashing sequences: 18%  \r",
      "Hashing sequences: 18%  \r",
      "Hashing sequences: 19%  \r",
      "Hashing sequences: 19%  \r",
      "Hashing sequences: 20%  \r",
      "Hashing sequences: 20%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 21%  \r",
      "Hashing sequences: 22%  \r",
      "Hashing sequences: 22%  \r",
      "Hashing sequences: 23%  \r",
      "Hashing sequences: 23%  \r",
      "Hashing sequences: 24%  \r",
      "Hashing sequences: 24%  \r",
      "Hashing sequences: 25%  \r",
      "Hashing sequences: 25%  \r",
      "Hashing sequences: 26%  \r",
      "Hashing sequences: 26%  \r",
      "Hashing sequences: 27%  \r",
      "Hashing sequences: 27%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 28%  \r",
      "Hashing sequences: 29%  \r",
      "Hashing sequences: 29%  \r",
      "Hashing sequences: 30%  \r",
      "Hashing sequences: 30%  \r",
      "Hashing sequences: 31%  \r",
      "Hashing sequences: 31%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 32%  \r",
      "Hashing sequences: 33%  \r",
      "Hashing sequences: 33%  \r",
      "Hashing sequences: 34%  \r",
      "Hashing sequences: 34%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 35%  \r",
      "Hashing sequences: 36%  \r",
      "Hashing sequences: 36%  \r",
      "Hashing sequences: 37%  \r",
      "Hashing sequences: 37%  \r",
      "Hashing sequences: 38%  \r",
      "Hashing sequences: 38%  \r",
      "Hashing sequences: 39%  \r",
      "Hashing sequences: 39%  \r",
      "Hashing sequences: 40%  \r",
      "Hashing sequences: 40%  \r",
      "Hashing sequences: 41%  \r",
      "Hashing sequences: 41%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 42%  \r",
      "Hashing sequences: 43%  \r",
      "Hashing sequences: 43%  \r",
      "Hashing sequences: 44%  \r",
      "Hashing sequences: 44%  \r",
      "Hashing sequences: 45%  \r",
      "Hashing sequences: 45%  \r",
      "Hashing sequences: 46%  \r",
      "Hashing sequences: 46%  \r",
      "Hashing sequences: 47%  \r",
      "Hashing sequences: 47%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 48%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 49%  \r",
      "Hashing sequences: 50%  \r",
      "Hashing sequences: 50%  \r",
      "Hashing sequences: 51%  \r",
      "Hashing sequences: 51%  \r",
      "Hashing sequences: 52%  \r",
      "Hashing sequences: 52%  \r",
      "Hashing sequences: 53%  \r",
      "Hashing sequences: 53%  \r",
      "Hashing sequences: 54%  \r",
      "Hashing sequences: 54%  \r",
      "Hashing sequences: 55%  \r",
      "Hashing sequences: 55%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 56%  \r",
      "Hashing sequences: 57%  \r",
      "Hashing sequences: 57%  \r",
      "Hashing sequences: 58%  \r",
      "Hashing sequences: 58%  \r",
      "Hashing sequences: 59%  \r",
      "Hashing sequences: 59%  \r",
      "Hashing sequences: 60%  \r",
      "Hashing sequences: 60%  \r",
      "Hashing sequences: 61%  \r",
      "Hashing sequences: 61%  \r",
      "Hashing sequences: 62%  \r",
      "Hashing sequences: 62%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 63%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 64%  \r",
      "Hashing sequences: 65%  \r",
      "Hashing sequences: 65%  \r",
      "Hashing sequences: 66%  \r",
      "Hashing sequences: 66%  \r",
      "Hashing sequences: 67%  \r",
      "Hashing sequences: 67%  \r",
      "Hashing sequences: 68%  \r",
      "Hashing sequences: 68%  \r",
      "Hashing sequences: 69%  \r",
      "Hashing sequences: 69%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 70%  \r",
      "Hashing sequences: 71%  \r",
      "Hashing sequences: 71%  \r",
      "Hashing sequences: 72%  \r",
      "Hashing sequences: 72%  \r",
      "Hashing sequences: 73%  \r",
      "Hashing sequences: 73%  \r",
      "Hashing sequences: 74%  \r",
      "Hashing sequences: 74%  \r",
      "Hashing sequences: 75%  \r",
      "Hashing sequences: 75%  \r",
      "Hashing sequences: 76%  \r",
      "Hashing sequences: 76%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 77%  \r",
      "Hashing sequences: 78%  \r",
      "Hashing sequences: 78%  \r",
      "Hashing sequences: 79%  \r",
      "Hashing sequences: 79%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 80%  \r",
      "Hashing sequences: 81%  \r",
      "Hashing sequences: 81%  \r",
      "Hashing sequences: 82%  \r",
      "Hashing sequences: 82%  \r",
      "Hashing sequences: 83%  \r",
      "Hashing sequences: 83%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 84%  \r",
      "Hashing sequences: 85%  \r",
      "Hashing sequences: 85%  \r",
      "Hashing sequences: 86%  \r",
      "Hashing sequences: 86%  \r",
      "Hashing sequences: 87%  \r",
      "Hashing sequences: 87%  \r",
      "Hashing sequences: 88%  \r",
      "Hashing sequences: 88%  \r",
      "Hashing sequences: 89%  \r",
      "Hashing sequences: 89%  \r",
      "Hashing sequences: 90%  \r",
      "Hashing sequences: 90%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 91%  \r",
      "Hashing sequences: 92%  \r",
      "Hashing sequences: 92%  \r",
      "Hashing sequences: 93%  \r",
      "Hashing sequences: 93%  \r",
      "Hashing sequences: 94%  \r",
      "Hashing sequences: 94%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 95%  \r",
      "Hashing sequences: 96%  \r",
      "Hashing sequences: 96%  \r",
      "Hashing sequences: 97%  \r",
      "Hashing sequences: 97%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 98%  \r",
      "Hashing sequences: 99%  \r",
      "Hashing sequences: 99%  \r",
      "Hashing sequences: 100%  \r",
      "Hashing sequences: 100%\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering:        100%    \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  283\n",
      "Largest swarm:     1434\n",
      "Max generations:   9\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGCGCTC.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleGCGCTC.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1337973 nt in 3850 sequences, longest 351 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%      \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  329\n",
      "Largest swarm:     1998\n",
      "Max generations:   9\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleGTCTCT.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleGTCTCT.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%  \n",
      "Database info:     2084423 nt in 6012 sequences, longest 349 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%                \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  540\n",
      "Largest swarm:     1986\n",
      "Max generations:   10\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleTCGCAT.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleTCGCAT.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1559649 nt in 4495 sequences, longest 351 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%              \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  520\n",
      "Largest swarm:     1673\n",
      "Max generations:   12\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleTCGTCA.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleTCGTCA.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%  \n",
      "Database info:     1434473 nt in 4139 sequences, longest 349 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%      \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  151\n",
      "Largest swarm:     2434\n",
      "Max generations:   10\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleTGTATG.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleTGTATG.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%   \n",
      "Database info:     1611854 nt in 4655 sequences, longest 352 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%            \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  584\n",
      "Largest swarm:     1679\n",
      "Max generations:   12\n",
      "Swarm 2.2.2 [Aug 27 2018 10:08:08]\n",
      "Copyright (C) 2012-2017 Torbjorn Rognes and Frederic Mahe\n",
      "https://github.com/torognes/swarm\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2014)\n",
      "Swarm: robust and fast clustering method for amplicon-based studies\n",
      "PeerJ 2:e593 https://doi.org/10.7717/peerj.593\n",
      "\n",
      "Mahe F, Rognes T, Quince C, de Vargas C, Dunthorn M (2015)\n",
      "Swarm v2: highly-scalable and high-resolution amplicon clustering\n",
      "PeerJ 3:e1420 https://doi.org/10.7717/peerj.1420\n",
      "\n",
      "CPU features:      mmx sse sse2 sse3 ssse3 sse4.1 sse4.2 popcnt avx\n",
      "Database file:     /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsampleunkown.fasta\n",
      "Output file:       /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleunkown.txt\n",
      "Resolution (d):    1\n",
      "Threads:           1\n",
      "Break OTUs:        Yes\n",
      "Fastidious:        No\n",
      "\n",
      "Reading database:  100%  \n",
      "Indexing database: 100%  \n",
      "Database info:     89801 nt in 260 sequences, longest 351 nt\n",
      "Hashing sequences: 100%  \n",
      "Clustering:        100%   \n",
      "Writing swarms:    100%  \n",
      "Writing seeds:     100%  \n",
      "\n",
      "Number of swarms:  209\n",
      "Largest swarm:     8\n",
      "Max generations:   3\n"
     ]
    }
   ],
   "source": [
    "!find /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/NOSPsample*.fasta \\\n",
    "| xargs basename -s .fasta | xargs -I{} \\\n",
    "swarm \\\n",
    "-o /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/{}.txt \\\n",
    "-w /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/{}.fasta \\\n",
    "-z \\\n",
    "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Derep/{}.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACACAC.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACAGCA.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACATGT.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACGACG.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleATATCG.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleATCAGT.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleCGACGA.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleCTCGCA.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleGATGAC.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleGCGCTC.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleGTCTCT.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleTCGCAT.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleTCGTCA.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleTGTATG.txt\n",
      "/Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleunkown.txt\n"
     ]
    }
   ],
   "source": [
    "!for filename in /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSP*.txt ; do \\\n",
    "  echo $filename | \\\n",
    "  grep -E '([A-Z])\\1*'\\\n",
    "; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USAGE\r\n",
      "  blastn [-h] [-help] [-import_search_strategy filename]\r\n",
      "    [-export_search_strategy filename] [-task task_name] [-db database_name]\r\n",
      "    [-dbsize num_letters] [-gilist filename] [-seqidlist filename]\r\n",
      "    [-negative_gilist filename] [-negative_seqidlist filename]\r\n",
      "    [-entrez_query entrez_query] [-db_soft_mask filtering_algorithm]\r\n",
      "    [-db_hard_mask filtering_algorithm] [-subject subject_input_file]\r\n",
      "    [-subject_loc range] [-query input_file] [-out output_file]\r\n",
      "    [-evalue evalue] [-word_size int_value] [-gapopen open_penalty]\r\n",
      "    [-gapextend extend_penalty] [-perc_identity float_value]\r\n",
      "    [-qcov_hsp_perc float_value] [-max_hsps int_value]\r\n",
      "    [-xdrop_ungap float_value] [-xdrop_gap float_value]\r\n",
      "    [-xdrop_gap_final float_value] [-searchsp int_value]\r\n",
      "    [-sum_stats bool_value] [-penalty penalty] [-reward reward] [-no_greedy]\r\n",
      "    [-min_raw_gapped_score int_value] [-template_type type]\r\n",
      "    [-template_length int_value] [-dust DUST_options]\r\n",
      "    [-filtering_db filtering_database]\r\n",
      "    [-window_masker_taxid window_masker_taxid]\r\n",
      "    [-window_masker_db window_masker_db] [-soft_masking soft_masking]\r\n",
      "    [-ungapped] [-culling_limit int_value] [-best_hit_overhang float_value]\r\n",
      "    [-best_hit_score_edge float_value] [-window_size int_value]\r\n",
      "    [-off_diagonal_range int_value] [-use_index boolean] [-index_name string]\r\n",
      "    [-lcase_masking] [-query_loc range] [-strand strand] [-parse_deflines]\r\n",
      "    [-outfmt format] [-show_gis] [-num_descriptions int_value]\r\n",
      "    [-num_alignments int_value] [-line_length line_length] [-html]\r\n",
      "    [-max_target_seqs num_sequences] [-num_threads int_value] [-remote]\r\n",
      "    [-version]\r\n",
      "\r\n",
      "DESCRIPTION\r\n",
      "   Nucleotide-Nucleotide BLAST 2.7.1+\r\n",
      "\r\n",
      "OPTIONAL ARGUMENTS\r\n",
      " -h\r\n",
      "   Print USAGE and DESCRIPTION;  ignore all other parameters\r\n",
      " -help\r\n",
      "   Print USAGE, DESCRIPTION and ARGUMENTS; ignore all other parameters\r\n",
      " -version\r\n",
      "   Print version number;  ignore other arguments\r\n",
      "\r\n",
      " *** Input query options\r\n",
      " -query <File_In>\r\n",
      "   Input file name\r\n",
      "   Default = `-'\r\n",
      " -query_loc <String>\r\n",
      "   Location on the query sequence in 1-based offsets (Format: start-stop)\r\n",
      " -strand <String, `both', `minus', `plus'>\r\n",
      "   Query strand(s) to search against database/subject\r\n",
      "   Default = `both'\r\n",
      "\r\n",
      " *** General search options\r\n",
      " -task <String, Permissible values: 'blastn' 'blastn-short' 'dc-megablast'\r\n",
      "                'megablast' 'rmblastn' >\r\n",
      "   Task to execute\r\n",
      "   Default = `megablast'\r\n",
      " -db <String>\r\n",
      "   BLAST database name\r\n",
      "    * Incompatible with:  subject, subject_loc\r\n",
      " -out <File_Out>\r\n",
      "   Output file name\r\n",
      "   Default = `-'\r\n",
      " -evalue <Real>\r\n",
      "   Expectation value (E) threshold for saving hits \r\n",
      "   Default = `10'\r\n",
      " -word_size <Integer, >=4>\r\n",
      "   Word size for wordfinder algorithm (length of best perfect match)\r\n",
      " -gapopen <Integer>\r\n",
      "   Cost to open a gap\r\n",
      " -gapextend <Integer>\r\n",
      "   Cost to extend a gap\r\n",
      " -penalty <Integer, <=0>\r\n",
      "   Penalty for a nucleotide mismatch\r\n",
      " -reward <Integer, >=0>\r\n",
      "   Reward for a nucleotide match\r\n",
      " -use_index <Boolean>\r\n",
      "   Use MegaBLAST database index\r\n",
      "   Default = `false'\r\n",
      " -index_name <String>\r\n",
      "   MegaBLAST database index name (deprecated; use only for old style indices)\r\n",
      "\r\n",
      " *** BLAST-2-Sequences options\r\n",
      " -subject <File_In>\r\n",
      "   Subject sequence(s) to search\r\n",
      "    * Incompatible with:  db, gilist, seqidlist, negative_gilist,\r\n",
      "   negative_seqidlist, db_soft_mask, db_hard_mask\r\n",
      " -subject_loc <String>\r\n",
      "   Location on the subject sequence in 1-based offsets (Format: start-stop)\r\n",
      "    * Incompatible with:  db, gilist, seqidlist, negative_gilist,\r\n",
      "   negative_seqidlist, db_soft_mask, db_hard_mask, remote\r\n",
      "\r\n",
      " *** Formatting options\r\n",
      " -outfmt <String>\r\n",
      "   alignment view options:\r\n",
      "     0 = Pairwise,\r\n",
      "     1 = Query-anchored showing identities,\r\n",
      "     2 = Query-anchored no identities,\r\n",
      "     3 = Flat query-anchored showing identities,\r\n",
      "     4 = Flat query-anchored no identities,\r\n",
      "     5 = BLAST XML,\r\n",
      "     6 = Tabular,\r\n",
      "     7 = Tabular with comment lines,\r\n",
      "     8 = Seqalign (Text ASN.1),\r\n",
      "     9 = Seqalign (Binary ASN.1),\r\n",
      "    10 = Comma-separated values,\r\n",
      "    11 = BLAST archive (ASN.1),\r\n",
      "    12 = Seqalign (JSON),\r\n",
      "    13 = Multiple-file BLAST JSON,\r\n",
      "    14 = Multiple-file BLAST XML2,\r\n",
      "    15 = Single-file BLAST JSON,\r\n",
      "    16 = Single-file BLAST XML2,\r\n",
      "    17 = Sequence Alignment/Map (SAM),\r\n",
      "    18 = Organism Report\r\n",
      "   \r\n",
      "   Options 6, 7, 10 and 17 can be additionally configured to produce\r\n",
      "   a custom format specified by space delimited format specifiers.\r\n",
      "   The supported format specifiers for options 6, 7 and 10 are:\r\n",
      "   \t    qseqid means Query Seq-id\r\n",
      "   \t       qgi means Query GI\r\n",
      "   \t      qacc means Query accesion\r\n",
      "   \t   qaccver means Query accesion.version\r\n",
      "   \t      qlen means Query sequence length\r\n",
      "   \t    sseqid means Subject Seq-id\r\n",
      "   \t sallseqid means All subject Seq-id(s), separated by a ';'\r\n",
      "   \t       sgi means Subject GI\r\n",
      "   \t    sallgi means All subject GIs\r\n",
      "   \t      sacc means Subject accession\r\n",
      "   \t   saccver means Subject accession.version\r\n",
      "   \t   sallacc means All subject accessions\r\n",
      "   \t      slen means Subject sequence length\r\n",
      "   \t    qstart means Start of alignment in query\r\n",
      "   \t      qend means End of alignment in query\r\n",
      "   \t    sstart means Start of alignment in subject\r\n",
      "   \t      send means End of alignment in subject\r\n",
      "   \t      qseq means Aligned part of query sequence\r\n",
      "   \t      sseq means Aligned part of subject sequence\r\n",
      "   \t    evalue means Expect value\r\n",
      "   \t  bitscore means Bit score\r\n",
      "   \t     score means Raw score\r\n",
      "   \t    length means Alignment length\r\n",
      "   \t    pident means Percentage of identical matches\r\n",
      "   \t    nident means Number of identical matches\r\n",
      "   \t  mismatch means Number of mismatches\r\n",
      "   \t  positive means Number of positive-scoring matches\r\n",
      "   \t   gapopen means Number of gap openings\r\n",
      "   \t      gaps means Total number of gaps\r\n",
      "   \t      ppos means Percentage of positive-scoring matches\r\n",
      "   \t    frames means Query and subject frames separated by a '/'\r\n",
      "   \t    qframe means Query frame\r\n",
      "   \t    sframe means Subject frame\r\n",
      "   \t      btop means Blast traceback operations (BTOP)\r\n",
      "   \t    staxid means Subject Taxonomy ID\r\n",
      "   \t  ssciname means Subject Scientific Name\r",
      "\r\n",
      "   \t  scomname means Subject Common Name\r\n",
      "   \tsblastname means Subject Blast Name\r\n",
      "   \t sskingdom means Subject Super Kingdom\r\n",
      "   \t   staxids means unique Subject Taxonomy ID(s), separated by a ';'\r\n",
      "   \t\t\t (in numerical order)\r\n",
      "   \t sscinames means unique Subject Scientific Name(s), separated by a ';'\r\n",
      "   \t scomnames means unique Subject Common Name(s), separated by a ';'\r\n",
      "   \tsblastnames means unique Subject Blast Name(s), separated by a ';'\r\n",
      "   \t\t\t (in alphabetical order)\r\n",
      "   \tsskingdoms means unique Subject Super Kingdom(s), separated by a ';'\r\n",
      "   \t\t\t (in alphabetical order) \r\n",
      "   \t    stitle means Subject Title\r\n",
      "   \tsalltitles means All Subject Title(s), separated by a '<>'\r\n",
      "   \t   sstrand means Subject Strand\r\n",
      "   \t     qcovs means Query Coverage Per Subject\r\n",
      "   \t   qcovhsp means Query Coverage Per HSP\r\n",
      "   \t    qcovus means Query Coverage Per Unique Subject (blastn only)\r\n",
      "   When not provided, the default value is:\r\n",
      "   'qaccver saccver pident length mismatch gapopen qstart qend sstart send\r\n",
      "   evalue bitscore', which is equivalent to the keyword 'std'\r\n",
      "   The supported format specifier for option 17 is:\r\n",
      "   \t        SQ means Include Sequence Data\r\n",
      "   \t        SR means Subject as Reference Seq\r\n",
      "   Default = `0'\r\n",
      " -show_gis\r\n",
      "   Show NCBI GIs in deflines?\r\n",
      " -num_descriptions <Integer, >=0>\r\n",
      "   Number of database sequences to show one-line descriptions for\r\n",
      "   Not applicable for outfmt > 4\r\n",
      "   Default = `500'\r\n",
      "    * Incompatible with:  max_target_seqs\r\n",
      " -num_alignments <Integer, >=0>\r\n",
      "   Number of database sequences to show alignments for\r\n",
      "   Default = `250'\r\n",
      "    * Incompatible with:  max_target_seqs\r\n",
      " -line_length <Integer, >=1>\r\n",
      "   Line length for formatting alignments\r\n",
      "   Not applicable for outfmt > 4\r\n",
      "   Default = `60'\r\n",
      " -html\r\n",
      "   Produce HTML output?\r\n",
      "\r\n",
      " *** Query filtering options\r\n",
      " -dust <String>\r\n",
      "   Filter query sequence with DUST (Format: 'yes', 'level window linker', or\r\n",
      "   'no' to disable)\r\n",
      "   Default = `20 64 1'\r\n",
      " -filtering_db <String>\r\n",
      "   BLAST database containing filtering elements (i.e.: repeats)\r\n",
      " -window_masker_taxid <Integer>\r\n",
      "   Enable WindowMasker filtering using a Taxonomic ID\r\n",
      " -window_masker_db <String>\r\n",
      "   Enable WindowMasker filtering using this repeats database.\r\n",
      " -soft_masking <Boolean>\r\n",
      "   Apply filtering locations as soft masks\r\n",
      "   Default = `true'\r\n",
      " -lcase_masking\r\n",
      "   Use lower case filtering in query and subject sequence(s)?\r\n",
      "\r\n",
      " *** Restrict search or results\r\n",
      " -gilist <String>\r\n",
      "   Restrict search of database to list of GI's\r\n",
      "    * Incompatible with:  negative_gilist, seqidlist, negative_seqidlist,\r\n",
      "   remote, subject, subject_loc\r\n",
      " -seqidlist <String>\r\n",
      "   Restrict search of database to list of SeqId's\r\n",
      "    * Incompatible with:  gilist, negative_gilist, negative_seqidlist, remote,\r\n",
      "   subject, subject_loc\r\n",
      " -negative_gilist <String>\r\n",
      "   Restrict search of database to everything except the listed GIs\r\n",
      "    * Incompatible with:  gilist, seqidlist, remote, subject, subject_loc\r\n",
      " -negative_seqidlist <String>\r\n",
      "   Restrict search of database to everything except the listed SeqIDs\r\n",
      "    * Incompatible with:  gilist, seqidlist, remote, subject, subject_loc\r\n",
      " -entrez_query <String>\r\n",
      "   Restrict search with the given Entrez query\r\n",
      "    * Requires:  remote\r\n",
      " -db_soft_mask <String>\r\n",
      "   Filtering algorithm ID to apply to the BLAST database as soft masking\r\n",
      "    * Incompatible with:  db_hard_mask, subject, subject_loc\r\n",
      " -db_hard_mask <String>\r\n",
      "   Filtering algorithm ID to apply to the BLAST database as hard masking\r\n",
      "    * Incompatible with:  db_soft_mask, subject, subject_loc\r\n",
      " -perc_identity <Real, 0..100>\r\n",
      "   Percent identity\r\n",
      " -qcov_hsp_perc <Real, 0..100>\r\n",
      "   Percent query coverage per hsp\r\n",
      " -max_hsps <Integer, >=1>\r\n",
      "   Set maximum number of HSPs per subject sequence to save for each query\r\n",
      " -culling_limit <Integer, >=0>\r\n",
      "   If the query range of a hit is enveloped by that of at least this many\r\n",
      "   higher-scoring hits, delete the hit\r\n",
      "    * Incompatible with:  best_hit_overhang, best_hit_score_edge\r\n",
      " -best_hit_overhang <Real, (>0 and <0.5)>\r\n",
      "   Best Hit algorithm overhang value (recommended value: 0.1)\r\n",
      "    * Incompatible with:  culling_limit\r\n",
      " -best_hit_score_edge <Real, (>0 and <0.5)>\r\n",
      "   Best Hit algorithm score edge value (recommended value: 0.1)\r\n",
      "    * Incompatible with:  culling_limit\r\n",
      " -max_target_seqs <Integer, >=1>\r\n",
      "   Maximum number of aligned sequences to keep \r\n",
      "   Not applicable for outfmt <= 4\r\n",
      "   Default = `500'\r\n",
      "    * Incompatible with:  num_descriptions, num_alignments\r\n",
      "\r\n",
      " *** Discontiguous MegaBLAST options\r\n",
      " -template_type <String, `coding', `coding_and_optimal', `optimal'>\r\n",
      "   Discontiguous MegaBLAST template type\r\n",
      "    * Requires:  template_length\r\n",
      " -template_length <Integer, Permissible values: '16' '18' '21' >\r\n",
      "   Discontiguous MegaBLAST template length\r\n",
      "    * Requires:  template_type\r\n",
      "\r\n",
      " *** Statistical options\r\n",
      " -dbsize <Int8>\r\n",
      "   Effective length of the database \r\n",
      " -searchsp <Int8, >=0>\r\n",
      "   Effective length of the search space\r\n",
      " -sum_stats <Boolean>\r\n",
      "   Use sum statistics\r\n",
      "\r\n",
      " *** Search strategy options\r\n",
      " -import_search_strategy <File_In>\r\n",
      "   Search strategy to use\r\n",
      "    * Incompatible with:  export_search_strategy\r\n",
      " -export_search_strategy <File_Out>\r\n",
      "   File name to record the search strategy used\r\n",
      "    * Incompatible with:  import_search_strategy\r\n",
      "\r\n",
      " *** Extension options\r\n",
      " -xdrop_ungap <Real>\r\n",
      "   X-dropoff value (in bits) for ungapped extensions\r\n",
      " -xdrop_gap <Real>\r\n",
      "   X-dropoff value (in bits) for preliminary gapped extensions\r\n",
      " -xdrop_gap_final <Real>\r\n",
      "   X-dropoff value (in bits) for final gapped alignment\r\n",
      " -no_greedy\r\n",
      "   Use non-greedy dynamic programming extension\r\n",
      " -min_raw_gapped_score <Integer>\r\n",
      "   Minimum raw gapped score to keep an alignment in the preliminary gapped and\r\n",
      "   traceback stages\r\n",
      " -ungapped\r\n",
      "   Perform ungapped alignment only?\r\n",
      " -window_size <Integer, >=0>\r\n",
      "   Multiple hits window size, use 0 to specify 1-hit algorithm\r\n",
      " -off_diagonal_range <Integer, >=0>\r\n",
      "   Number of off-diagonals to search for the 2nd hit, use 0 to turn off\r\n",
      "   Default = `0'\r\n",
      "\r\n",
      " *** Miscellaneous options\r\n",
      " -parse_deflines\r\n",
      "   Should the query and subject defline(s) be parsed?\r\n",
      " -num_threads <Integer, (>=1 and =<4)>\r\n",
      "   Number of threads (CPUs) to use in the BLAST search\r\n",
      "   Default = `1'\r\n",
      "    * Incompatible with:  remote\r\n",
      " -remote\r\n",
      "   Execute search remotely?\r\n",
      "    * Incompatible with:  gilist, seqidlist, negative_gilist,\r\n",
      "   negative_seqidlist, subject_loc, num_threads\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!blastn -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">M02215:3:000000000-B9JT7:1:1101:14861:113761:N:0:1;size=842;\r\n",
      "TCTAAGTCATATTACGAGCCACTCTGGTGGTGCAGTTGATTTAGCTATTTTCAGTTTACATTTATCTGGAGCGAGCAGTATTTTAGGGGCGATTAACTTTATTACCACTATCTTTAACATGCGTGGGCCTGGTCTGGGCTTCCATCGCTTACCTTTATTTGTGTGGTCTGTTCTGATTACGGCCTTCTTACTTCTTCTCTCTTTACCGGTTTTAGCGGGAGCGATTACGATGCTGTTAACGGATCGTAACTTCAATACCTCGTTCTTTGATCCGGCGGGCGGAGGTGACCCTATTTTGTTCCAGCACCTTTTTTGATTCTTCGGCCACCCCGAAGTCTAGTGTG\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:22049:153961:N:0:1;size=4699;\r\n",
      "TCTAAGTCATATTACGAGCCACTCTGGTGGTGCAGTTGATTTAGCTATTTTCAGTTTACATTTATCTGGAGCGAGCAGTATTTTAGGGGCGATTAACTTTATTACCACTATCTTTAACATGCGTGGGCCTGGTCTGGGCTTCCATCGCTTACCTTTATTTGTGTGGTCTGTTCTGATTACGGCCTTCTTACTTCTTCTCTCTTTACCGGTTTTAGCGGGAGCGATTACGATGCTGTTAACGGATCGTAACTTCAATACCTCGTTCTTTGATCCGGCGGGCGGAGGTGACCCTATTTTGTTCCAGCACCTTTTTTGATTCTTCGGCCACCCCGAGGTCTAGTGTGTCCC\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:18452:138431:N:0:1;size=327;\r\n",
      "TCTCTCAAGTAATGTTGCACATGCGGGAAGATCGGTTGACTTTGCCATTTTCTCATTACATTTGGCGGGAGTTAGTTCTATTTTAGGAGCTGTTAATTTTATTAGTACCCTTGGTAATTTACGTGTATTTGGTATAATTCTTGACCGAATGCCCCTATTTGCATGGTCTGTTCTGATTACCGCAGTATTACTATTGTTGTCTTTACCTGTGTTAGCCGGTGCCATTACTATACTTCTAACTGATCGAAACCTTAATTCTTCTTTTTATGATACTAGGGGAGGCGGGGATCCAATTTTATATCAACATTTATTCTGATTCTTCGGCCACCCCGAGGTCTAGTGTG\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:10680:207211:N:0:1;size=1466;\r\n",
      "TCTCTCAAGTAATGTTGCACATGCGGGAAGATCGGTTGACTTTGCCATTTTCTCATTACATTTGGCGGGAGTTAGTTCTATTTTAGGAGCTGTTAATTTTATTAGTACCCTTGGTAATTTACGTGTATTTGGTATAATTCTTGACCGAATGCCCCTATTTGCATGGTCTGTTCTGATTACCGCAGTATTACTATTGTTGTCTTTACCTGTGTTAGCCGGTGCCATTACTATACTTCTAACTGATCGAAACCTTAATTCTTCTTTTTATGATACTAGGGGAGGCGGGGATCCAATTTTATATCAACATTTATTCTGATTCTTCGGCCACCCCGAGGTCTAGTGTGTCCC\r\n",
      ">M02215:3:000000000-B9JT7:1:1101:27225:182981:N:0:1;size=18;\r\n",
      "TCTAAGTCATATTACGAGCCACTCTGGTGGTGCAGTTGATTTAGCTATTTTCAGTTTACATTTATCTGGAGCGAGCAGTATTTTAGGGGCGATTAACTTTATTACCACTATCTTTAACATGCGTGGGCCTGGTCTGGGCTTCCATCGCTTACCTTTATTTGTGTGGTCTGTTCTGATTACGGCCTTCTTACTTCTTCTCTCTTTACCGGTTTTAGCGGGAGCGATTACGATGCTGTTAACGGATCGTAACTTCAATACCTCGTTCTTTGATCCGGCGGGCGGAGGTGACCCTATTTTGTTCCAGCACCTTTTTTGATTCTTCGGCCACCCCGAAGTCTAGTGTGTCTG\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/kellycribari/Documents/Bioinformatics/GitHub/Cribari-eDNA/Cluster/NOSPsampleACACAC.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mblast_formatter\u001b[m\u001b[m   \u001b[31mblastx\u001b[m\u001b[m            \u001b[31mmakembindex\u001b[m\u001b[m       \u001b[31mtblastn\u001b[m\u001b[m\r\n",
      "\u001b[31mblastdb_aliastool\u001b[m\u001b[m \u001b[31mconvert2blastmask\u001b[m\u001b[m \u001b[31mmakeprofiledb\u001b[m\u001b[m     \u001b[31mtblastx\u001b[m\u001b[m\r\n",
      "\u001b[31mblastdbcheck\u001b[m\u001b[m      \u001b[31mdeltablast\u001b[m\u001b[m        \u001b[31mpsiblast\u001b[m\u001b[m          \u001b[31mupdate_blastdb.pl\u001b[m\u001b[m\r\n",
      "\u001b[31mblastdbcmd\u001b[m\u001b[m        \u001b[31mdustmasker\u001b[m\u001b[m        \u001b[31mrpsblast\u001b[m\u001b[m          \u001b[31mwindowmasker\u001b[m\u001b[m\r\n",
      "\u001b[31mblastn\u001b[m\u001b[m            \u001b[31mlegacy_blast.pl\u001b[m\u001b[m   \u001b[31mrpstblastn\u001b[m\u001b[m\r\n",
      "\u001b[31mblastp\u001b[m\u001b[m            \u001b[31mmakeblastdb\u001b[m\u001b[m       \u001b[31msegmasker\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Users/kellycribari/Documents/Bioinformatics/ncbi-blast-2.7.1+/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "blasting = \"/Users/kellycribari/Documents/Bioinformatics/ncbi-blast-2.7.1+/bin/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
